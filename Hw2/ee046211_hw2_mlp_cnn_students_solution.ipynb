{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "ee046211_hw2_mlp_cnn_students_solution.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzV9wsJ5pGhf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "## HW2 - Multilayer NNs and Convolutional NNs\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq2c8X93pGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/clouds/96/000000/keyboard.png\" style=\"height:50px;display:inline\"> Keyboard Shortcuts\n",
        "---\n",
        "* Run current cell: **Ctrl + Enter**\n",
        "* Run current cell and move to the next: **Shift + Enter**\n",
        "* Show lines in a code cell: **Esc + L**\n",
        "* View function documentation: **Shift + Tab** inside the parenthesis or `help(name_of_module)`\n",
        "* New cell below: **Esc + B**\n",
        "* Delete cell: **Esc + D, D** (two D's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZybn3NpGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/information.png\" style=\"height:50px;display:inline\"> Students Information\n",
        "---\n",
        "* Fill in\n",
        "\n",
        "|Name     |Campus Email| ID  |\n",
        "|---------|--------------------------------|----------|\n",
        "|Roy Elkabetz| roy-e@campus.technion.ac.il| 300427259|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDK5zqhdpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/upload-to-cloud.png\" style=\"height:50px;display:inline\"> Submission Guidelines\n",
        "---\n",
        "* Maximal garde: 100.\n",
        "* Submission only in **pairs**. \n",
        "    * Please make sure you have registered your group in Moodle (there is a group creation component on the Moodle where you need to create your group and assign members).\n",
        "* **No handwritten submissions.** You can choose whether to answer in a Markdown cell in this notebook or attach a PDF with your answers.\n",
        "* <a style='color:red'> SAVE THE NOTEBOOKS WITH THE OUTPUT, CODE CELLS THAT WERE NOT RUN WILL NOT GET ANY POINTS! </a>\n",
        "* What you have to submit:\n",
        "    * If you have answered the questions in the notebook, you should submit this file only, with the name: `ee046211_hw2_id1_id2.ipynb`.\n",
        "    * If you answered the questionss in a different file you should submit a `.zip` file with the name `ee046211_hw2_id1_id2.zip` with content:\n",
        "        * `ee046211_hw2_id1_id2.ipynb` - the code tasks\n",
        "        * `ee046211_hw2_id1_id2.pdf` - answers to questions.\n",
        "    * No other file-types (`.py`, `.docx`...) will be accepted.\n",
        "* Submission on the course website (Moodle).\n",
        "* **Latex in Colab** - in some cases, Latex equations may no be rendered. To avoid this, make sure to not use *bullets* in your answers (\"* some text here with Latex equations\" -> \"some text here with Latex equations\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSj_UufpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/online.png\" style=\"height:50px;display:inline\"> Working Online and Locally\n",
        "---\n",
        "* You can choose your working environment:\n",
        "    1. `Jupyter Notebook`, **locally** with <a href=\"https://www.anaconda.com/distribution/\">Anaconda</a> or **online** on <a href=\"https://colab.research.google.com/\">Google Colab</a>\n",
        "        * Colab also supports running code on GPU, so if you don't have one, Colab is the way to go. To enable GPU on Colab, in the menu: `Runtime`$\\rightarrow$ `Change Runtime Type` $\\rightarrow$`GPU`.\n",
        "    2. Python IDE such as <a href=\"https://www.jetbrains.com/pycharm/\">PyCharm</a> or <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>.\n",
        "        * Both allow editing and running Jupyter Notebooks.\n",
        "\n",
        "* Please refer to `Setting Up the Working Environment.pdf` on the Moodle or our GitHub (https://github.com/taldatech/ee046211-deep-learning) to help you get everything installed.\n",
        "* If you need any technical assistance, please go to our Piazza forum (`hw2` folder) and describe your problem (preferably with images)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlp1Fp4ppGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "\n",
        "* [Part 1 - Theory](#-Part-1---Theory)\n",
        "    * [Q1 - Generalization in A Teacher-Student Setup](#-Question-1--Generalization-in-A-Teacher-Student-Setup)\n",
        "    * [Q2 - Backpropagation By Hand](#-Question-2---Backpropagation-By-Hand)\n",
        "    * [Q3 - Deep Double Descent](#-Question-3---Deep-Double-Descent)\n",
        "    * [Q4 - Initialization](#-Question-4---Initialization)\n",
        "    * [Q5 - Equivarinace](#-Question-5--Equivarinace)\n",
        "    * [Q6 - VGG Architecture](#-Question-6--VGG-Architecture)\n",
        "* [Part 2 - Code Assignments](#-Part-2---Code-Assignments)\n",
        "    * [Task 1 - The Importance of Activation and Initialization](#-Task-1---The-Importance-of-Activation-and-Initialization)\n",
        "    * [Task 2 - FashionMNIST Deep Classifer](#-Task-2---FashionMNIST-Deep-Classifer)\n",
        "    * [Task 3 - Design a CNN](#-Task-3---Design-a-CNN)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtSiQX_pGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/cute-clipart/64/000000/ball-point-pen.png\" style=\"height:50px;display:inline\"> Part 1 - Theory\n",
        "---\n",
        "* You can choose whether to answser these straight in the notebook (Markdown + Latex) or use another editor (Word, LyX, Latex, Overleaf...) and submit an additional PDF file, **but no handwritten submissions**.\n",
        "* You can attach additional figures (drawings, graphs,...) in a separate PDF file, just make sure to refer to them in your answers.\n",
        "\n",
        "* $\\large\\LaTeX$ <a href=\"https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index\">Cheat-Sheet</a> (to write equations)\n",
        "    * <a href=\"http://tug.ctan.org/info/latex-refsheet/LaTeX_RefSheet.pdf\">Another Cheat-Sheet</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsqSFZG1pGhj"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 1 -Generalization in A Teacher-Student Setup\n",
        "---\n",
        "\n",
        "Recall from lecture 4 the Bayes Risk $\\mathcal{\\overline{R}}(w)$: $$ \\mathcal{\\overline{R}}(w) \\triangleq \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) } \\left[\\mathcal{R}\\right], $$ where, $$ \\mathcal{R}(w_{\\mu}) = ||w_{\\mu}-w_{true}||^2 = ||(H_{\\mu}^{-1}H-I)w_{true} + H_{\\mu}^{-1}X^T\\epsilon||^2 $$\n",
        "\n",
        "Prove:\n",
        "\n",
        "$$ \\mathcal{R}(w_{\\mu}) = \\sum_{i=1}^d \\frac{(\\sigma_w^2/d) \\mu^2 + \\sigma_{\\epsilon}^2 \\lambda_i}{(\\lambda_i + \\mu)^2} $$\n",
        "\n",
        "Hints:\n",
        "* $\\mathbb{E} \\left[\\epsilon^TXH_{\\mu}^{-1}H_{\\mu}^{-1}X^T\\epsilon \\right] = \\sum_{i,j}^N\\mathbb{E}[\\epsilon_i \\epsilon_j] \\left(XH_{\\mu}^{-1} \\right)_i\\left(H_{\\mu}^{-1}X^T \\right)_j$\n",
        "\n",
        "* $\\mathbb{E}[\\epsilon_i \\epsilon_j] = \\sigma_{\\epsilon}^2 \\delta_{ij}$\n",
        "\n",
        "* $\\sum_{i=1}^N \\left(XH_{\\mu}^{-1} \\right)_i\\left(H_{\\mu}^{-1}X^T \\right)_i = Tr\\left[XH_{\\mu}^{-2}X^T \\right] $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIqCnSWbJ4PY"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 1 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "Let us start by calculating $\\overline{\\mathcal{R}}(w_\\mu)$ from $\\mathcal{R}(w_\\mu)$. First lets simplify $\\mathcal{R}(w_\\mu)$\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "    \\mathcal{R}(w_{\\mu}) &= ||(H_{\\mu}^{-1}H-I)w_{true} + H_{\\mu}^{-1}X^T\\epsilon||^2\\\\\n",
        "                         &= \\left((H_{\\mu}^{-1}H-I)w_{true} + H_{\\mu}^{-1}X^T\\epsilon\\right)\\left((H_{\\mu}^{-1}H-I)w_{true} + H_{\\mu}^{-1}X^T\\epsilon\\right)^T\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "before moving forward with the computation it would be easier do define new variables\n",
        "\n",
        "\\begin{align}\n",
        "  a &\\triangleq (H_{\\mu}^{-1}H-I)w_{true},\\quad b \\triangleq H_{\\mu}^{-1}X^T\\epsilon\n",
        "\\end{align}\n",
        "\n",
        "We can simplify the relation above\n",
        "\n",
        "\\begin{align}\n",
        "    \\mathcal{R}(w_{\\mu}) &= \\left(a + b\\right)\\left(a + b\\right)^T\\\\\n",
        "                         &= aa^T + ab^T + ba^T + bb^T\\\\\n",
        "\\end{align}\n",
        "\n",
        "Then we can substitute this into the Bayes risk\n",
        "\n",
        "\\begin{align}\n",
        "  \\mathcal{\\overline{R}}(w_{\\mu}) &\\triangleq \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) } \\left[\\mathcal{R}(w_\\mu)\\right]\\\\\n",
        "  &= \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) } \\left[aa^T + ab^T + ba^T + bb^T\\right]\\\\\n",
        "  &= \\mathbb{E}\\left[aa^T\\right] + \\mathbb{E}\\left[ab^T\\right] + \\mathbb{E}\\left[ba^T\\right] + \\mathbb{E}\\left[bb^T\\right]\\\\\n",
        "\\end{align}\n",
        "\n",
        "Next, let us work them out one by one:\n",
        "\n",
        "\\begin{align}\n",
        "  \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[aa^T\\right] &= \\mathbb{E}_{w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[(H_{\\mu}^{-1}H-I)w_{true}w_{true}^T(H_{\\mu}^{-1}H-I)^T\\right]\\\\\n",
        "  &= \\sum_{i, j}^{N}\\mathbb{E}\\left[(w_{true})_i(w_{true})_j\\right]\\left(H_{\\mu}^{-1}H-I\\right)_i\\left(HH_{\\mu}^{-1}-I\\right)_j\\\\\n",
        "  &= \\sum_{i, j}^{N}\\frac{\\sigma_{w}^{2}}{d}\\delta_{ij}\\left(H_{\\mu}^{-1}H-I\\right)_i\\left(HH_{\\mu}^{-1}-I\\right)_j\\\\\n",
        "  &= \\frac{\\sigma_{w}^{2}}{d}\\sum_{i}^{N}\\left(H_{\\mu}^{-1}H-I\\right)_i\\left(HH_{\\mu}^{-1}-I\\right)_j\\\\\n",
        "  &= \\frac{\\sigma_{w}^{2}}{d}Tr\\left[\\left(H_{\\mu}^{-1}H-I\\right)\\left(HH_{\\mu}^{-1}-I\\right)\\right]\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Next,\n",
        "\n",
        "\\begin{align}\n",
        "  \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[ab^T\\right] &= \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[\\left(H_{\\mu}^{-1}H-I\\right)w_{true} \\left(H_{\\mu}^{-1}X^T\\epsilon\\right)^T\\right]\\\\\n",
        "  &= \\mathbb{E}_{w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[\\left(H_{\\mu}^{-1}H-I\\right)w_{true}\\right] \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I)}\\left[\\left(H_{\\mu}^{-1}X^T\\epsilon\\right)^T\\right]\\\\\n",
        "  &= 0\\cdot 0\n",
        "  &= 0\n",
        "\\end{align}\n",
        "\n",
        "and same goes for\n",
        "$$\\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[ba^T\\right]=0$$\n",
        "\n",
        "Last\n",
        "\n",
        "\\begin{align}\n",
        "  \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I), w_{true} \\sim \\mathcal{N}(0,\\frac{\\sigma_w^2}{d}I) }\\left[bb^T\\right] &= \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I)}\\left[\\left(H_{\\mu}^{-1}X^T\\epsilon\\right)\\left(H_{\\mu}^{-1}X^T\\epsilon\\right)^T\\right]\\\\\n",
        "  &= \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2I)}\\left[H_{\\mu}^{-1}X^T\\epsilon\\epsilon^T X\\left(H_{\\mu}^{-1}\\right)^T\\right]\\\\\n",
        "  &= \\sum_{i, j}^{N}\\mathbb{E}[\\epsilon_i \\epsilon_j] \\left(H_{\\mu}^{-1}X^T \\right)_i\\left(X H_{\\mu}^{-1} \\right)_j\\\\\n",
        "  &=\\sum_{i, j}^{N}\\sigma_{\\epsilon}^2 \\delta_{ij} \\left(H_{\\mu}^{-1}X^T \\right)_i\\left(X H_{\\mu}^{-1}  \\right)_j\\\\\n",
        "  &=\\sigma_{\\epsilon}^2 Tr\\left[XH_{\\mu}^{-2}X^T \\right]\n",
        "\\end{align}\n",
        "\n",
        "So, finally we end up with the next equality\n",
        "\n",
        "\\begin{align}\n",
        "  \\overline{\\mathcal{R}}(w_\\mu) &= \\frac{\\sigma_{w}^{2}}{d}Tr\\left[\\left(H_{\\mu}^{-1}H-I\\right)\\left(HH_{\\mu}^{-1}-I\\right)\\right] + \\sigma_{\\epsilon}^2 Tr\\left[XH_{\\mu}^{-2}X^T \\right]\n",
        "\\end{align}\n",
        "\n",
        "Again, let us work out term by term, starting with the right most one\n",
        "\n",
        "\\begin{align}\n",
        "  Tr\\left[XH_{\\mu}^{-2}X^T \\right] &= Tr\\left[X^TXH_{\\mu}^{-2} \\right]\\\\\n",
        "    &= Tr\\left[X^TX \\left(\\mu I+X^TX\\right)^{-2} \\right]\n",
        "\\end{align}\n",
        "\n",
        "recall that $X^T X$ is positive semi-definite matrix so it can be decomposed to $$X^T X = U \\lambda U^T$$ where $\\lambda$ is a diagonal matrix with non-negative eigenvalues and $U$ is a unitary matrix with eigenvectors on columns.  \n",
        "\n",
        "Then, \n",
        "\n",
        "\\begin{align}\n",
        "  Tr\\left[XH_{\\mu}^{-2}X^T \\right] &= Tr\\left[X^TX \\left(\\mu I+X^TX\\right)^{-2} \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(\\mu I+U \\lambda U^T\\right)^{-2} \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(\\mu UIU^T+U \\lambda U^T\\right)^{-2} \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(U\\left(\\mu I+ \\lambda\\right) U^T\\right)^{-2} \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(\\left(U\\left(\\mu I+ \\lambda\\right) U^T\\right)^{-1}\\right)^{2} \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(\\left(U^T\\right)^{-1}\\left(\\mu I+ \\lambda\\right)^{-1} U^{-1}\\right)^{2} \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(\\left(U^T\\right)^{-1}\\left(\\mu I+ \\lambda\\right)^{-2} U^{-1}\\right) \\right]\\\\\n",
        "  &= Tr\\left[U \\lambda U^T \\left(U\\left(\\mu I+ \\lambda\\right)^{-2} U^T\\right) \\right]\\\\\n",
        "  &= Tr\\left[U^TU \\lambda U^T U\\left(\\mu I+ \\lambda\\right)^{-2}  \\right]\\\\\n",
        "  &= Tr\\left[ \\lambda \\left(\\mu I+ \\lambda\\right)^{-2}  \\right]\\\\\n",
        "  &= \\sum_{i=1}^{d} \\frac{\\lambda_i}{ \\left(\\mu +\\lambda_i\\right)^2}\n",
        "\\end{align}\n",
        "\n",
        "Next let us workout the left term\n",
        "\n",
        "\\begin{align}\n",
        "  Tr\\left[\\left(H_{\\mu}^{-1}H-I\\right)\\left(HH_{\\mu}^{-1}-I\\right)\\right] &= Tr\\left[H_{\\mu}^{-1}H HH_{\\mu}^{-1}\\right] - Tr\\left[H_{\\mu}^{-1}H\\right] - Tr\\left[ HH_{\\mu}^{-1}\\right] + Tr\\left[I^2\\right]\\\\\n",
        "  &= Tr\\left[H_{\\mu}^{-2}H^2 \\right] - Tr\\left[H_{\\mu}^{-1}H\\right] - Tr\\left[ HH_{\\mu}^{-1}\\right] + Tr\\left[I^2\\right]\\\\\n",
        "  &= Tr\\left[\\left(U\\lambda U^T + \\mu I\\right)^{-2}U\\lambda^2 U^T \\right] - 2Tr\\left[\\left(U\\lambda U^T + \\mu I\\right)^{-1}U\\lambda U^T\\right] + d\\\\\n",
        "  &= Tr\\left[\\left(U^T\\right)^{-1}\\left(\\lambda + \\mu I\\right)^{-2}U^{-1}U\\lambda^2 U^T \\right] - 2Tr\\left[\\left(U^T\\right)^{-1}\\left(\\lambda + \\mu I\\right)^{-1}U^{-1}U\\lambda U^T\\right] + d\\\\\n",
        "  &= Tr\\left[U\\left(\\lambda + \\mu I\\right)^{-2} \\lambda^2 U^T \\right] - 2Tr\\left[U\\left(\\lambda + \\mu I\\right)^{-1}\\lambda U^T\\right] + d\\\\\n",
        "  &= Tr\\left[\\left(\\lambda + \\mu I\\right)^{-2} \\lambda^2 \\right] - 2Tr\\left[\\left(\\lambda + \\mu I\\right)^{-1}\\lambda \\right] + d\\\\\n",
        "  &= \\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}}{\\left(\\lambda_i + \\mu \\right)^{2}}   - 2\\sum_{i=1}^{d}\\frac{\\lambda_{i}}{\\left(\\lambda_i + \\mu \\right)} + d\\\\\n",
        "  &= \\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}}{\\left(\\lambda_i + \\mu \\right)^{2}}   - 2\\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}+\\lambda_{i}\\mu}{\\left(\\lambda_i + \\mu \\right)^{2}} + d\\\\\n",
        "  &= - \\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}+2\\lambda_{i}\\mu}{\\left(\\lambda_i + \\mu \\right)^{2}} + d\\\\\n",
        "  &= - \\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}+2\\lambda_{i}\\mu}{\\left(\\lambda_i + \\mu \\right)^{2}} + \\sum_{i=1}^{d}\\frac{\\left(\\lambda_i + \\mu \\right)^{2}}{\\left(\\lambda_i + \\mu \\right)^{2}}\\\\\n",
        "  &= - \\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}+2\\lambda_{i}\\mu}{\\left(\\lambda_i + \\mu \\right)^{2}} + \\sum_{i=1}^{d}\\frac{\\lambda_{i}^{2}+2\\lambda_{i}\\mu + \\mu^{2}}{\\left(\\lambda_i + \\mu \\right)^{2}}\\\\\n",
        "  &= \\sum_{i=1}^{d}\\frac{\\mu^{2}}{\\left(\\lambda_i + \\mu \\right)^{2}}\n",
        "\\end{align}\n",
        "\n",
        "Finally we get\n",
        "\n",
        "\\begin{align}\n",
        "   \\overline{\\mathcal{R}}(w_\\mu) &= \\frac{\\sigma_{w}^{2}}{d}\\sum_{i=1}^{d}\\frac{\\mu^{2}}{\\left(\\lambda_i + \\mu \\right)^{2}} + \\sigma_{\\epsilon}^2\\sum_{i=1}^{d} \\frac{\\lambda_i}{ \\left(\\mu +\\lambda_i\\right)^2}\\\\\n",
        "  \\overline{\\mathcal{R}}(w_\\mu) &= \\boxed{\\sum_{i=1}^{d} \\frac{\\left(\\frac{\\sigma_{w}^{2}}{d}\\right)\\mu^{2}+\\sigma_{\\epsilon}^2\\lambda_i}{ \\left(\\mu +\\lambda_i\\right)^2}}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "and we are done.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div style=\"text-align: right\"> $\\color{#4CBB17}{\\rule{1.7ex}{1.7ex}}$ </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezVG7aY2J4PZ"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 2 - Backpropagation By Hand\n",
        "---\n",
        "Consider the following network:\n",
        "<img src=\"https://raw.githubusercontent.com/taldatech/ee046211-deep-learning/main/assets/backprop_by_hand_ex1.png\" style=\"height:300px\">\n",
        "\n",
        "We will work with one sample for this example, but it can be extended to mini-batches.\n",
        "\n",
        "* Input: $x = \\begin{bmatrix} 1 \\\\ 4 \\\\ 5 \\end{bmatrix} \\in \\mathbb{R}^3$\n",
        "* Output (target): $ t = \\begin{bmatrix} 0.1 \\\\ 0.05 \\end{bmatrix} \\in \\mathbb{R}^2 $\n",
        "* Number of Hidden Layers: 1\n",
        "* Activation: Sigmoid for both hidden and output layers\n",
        "* Loss Functions: MSE\n",
        "\n",
        "We initialize the weights and biases to random values as follows:\n",
        "<img src=\"https://raw.githubusercontent.com/taldatech/ee046211-deep-learning/main/assets/backprop_by_hand_ex2.png\" style=\"height:300px\">\n",
        "\n",
        "1. Perform one forward pass and calculate the MSE.\n",
        "2. Perform backpropagation (one backward pass, i.e., calculate the gradients).\n",
        "3. With a learning rate of $\\alpha = 0.01$, what are the new values of the weights after performing the forward pass and backward pass (assume we use SGD)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEADfHzyJ4Pa"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 2 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "\n",
        "1. We notice that it is possible to write the given network in a vectorized notaion as follows\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "O &= \\phi\\left(W_2^T \\phi\\left(W_1^T X + b_1\\right) + b_2\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "where $O\\in \\mathbb{R^{2\\times 1}}$ is the output of the network, $X\\in \\mathbb{R^{3\\times 1}}$ is the input and $W_l,b_l$ are the weights which are given (from the figure above) by \n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    W_1 = \n",
        "\\left(\\begin{array}{ccc}\n",
        "0.1 & 0.2 \\\\\n",
        "0.3 & 0.4 \\\\\n",
        "0.5 & 0.6\n",
        "\\end{array}\\right)\n",
        ",\\quad\n",
        "W_2 = \n",
        "\\left(\\begin{array}{cc}\n",
        "0.7 & 0.8 \\\\\n",
        "0.9 & 0.1 \n",
        "\\end{array}\\right)\n",
        ",\\quad\n",
        "b_1 = \n",
        "\\left(\\begin{array}{c}\n",
        "0.5\\\\\n",
        "0.5\n",
        "\\end{array}\\right)\n",
        ",\\quad\n",
        "b_2 = \n",
        "\\left(\\begin{array}{c}\n",
        "0.5\\\\\n",
        "0.5\n",
        "\\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Now we can calculate the output of the network, $O$, using a forward pass, lets start by calculating the hidden layer,\n",
        "$h$, values:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    h &= \\phi\\left( W_1^T X +b_1\\right)\\\\\n",
        "      &= \\phi\\left(\n",
        "        \\left(\\begin{array}{cc}\n",
        "            0.1 & 0.3 & 0.5 \\\\\n",
        "            0.2 & 0.4 & 0.6\n",
        "        \\end{array}\\right)\n",
        "        \\left[\\begin{array}{c}\n",
        "            1\\\\\n",
        "            4\\\\\n",
        "            5\n",
        "        \\end{array}\\right]+\n",
        "        \\left(\\begin{array}{c}\n",
        "            0.5\\\\\n",
        "            0.5\n",
        "        \\end{array}\\right)\n",
        "        \\right)\\\\\\\\\n",
        "      &=\\phi\\left(\n",
        "        \\left(\\begin{array}{c}\n",
        "            4.3\\\\\n",
        "            5.3\n",
        "        \\end{array}\\right)\n",
        "        \\right)\\\\\\\\\n",
        "      &=\\left(\\begin{array}{c}\n",
        "            \\phi(4.3)\\\\\n",
        "            \\phi(5.3)\n",
        "        \\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "where $\\phi(x) = \\frac{1}{1+\\exp(-x)}$. In the same way lets calculate $O$\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    O &= \\phi\\left( W_2^T h +b_2\\right)\\\\\n",
        "      &= \\phi\\left(\n",
        "        \\left(\\begin{array}{cc}\n",
        "            0.7 & 0.9\\\\\n",
        "            0.8 & 0.1\n",
        "        \\end{array}\\right)\n",
        "        \\left(\\begin{array}{c}\n",
        "            \\phi(4.3)\\\\\n",
        "            \\phi(5.3)\n",
        "        \\end{array}\\right)+\n",
        "        \\left(\\begin{array}{c}\n",
        "            0.5\\\\\n",
        "            0.5\n",
        "        \\end{array}\\right)\n",
        "        \\right)\\\\\\\\\n",
        "      &=\\left(\\begin{array}{c}\n",
        "            \\phi(0.7\\phi(4.3)+0.9\\phi(5.3)+0.5)\\\\\n",
        "            \\phi(0.8\\phi(4.3)+0.1\\phi(5.3)+0.5)\n",
        "        \\end{array}\\right)\n",
        "\\end{align}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8O8UBChZJ4Pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f4df8de-4fe0-495d-acfd-d630a249170c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "# Input\n",
        "X = np.array([1., 4., 5.])\n",
        "\n",
        "# Weights\n",
        "W1 = np.array([[0.1, 0.2],\n",
        "               [0.3, 0.4],\n",
        "               [0.5, 0.6]])\n",
        "b1 = np.array([0.5, 0.5])\n",
        "\n",
        "W2 = np.array([[0.7, 0.8],\n",
        "               [0.9, 0.1]])\n",
        "b2 = np.array([0.5, 0.5])\n",
        "\n",
        "# calculating the hidden layer values\n",
        "h = sigmoid(np.transpose(W1) @ X + b1)\n",
        "\n",
        "# calculating the output layer values\n",
        "O = sigmoid(np.transpose(W2) @ h + b2)\n",
        "\n",
        "print('h = {}'.format(h))\n",
        "print('O = {}'.format(O))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "h = [0.98661308 0.9950332 ]\n",
            "O = [0.88955061 0.80039961]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-ya2B0myJ4Pb"
      },
      "source": [
        "So we get that\n",
        "$\n",
        "O = \\left(\\begin{array}{c}\n",
        "            \\phi(0.7\\phi(4.3)+0.9\\phi(5.3)+0.5)\\\\\n",
        "            \\phi(0.8\\phi(4.3)+0.1\\phi(5.3)+0.5)\n",
        "        \\end{array}\\right)\n",
        "    =\\left(\\begin{array}{c}\n",
        "             0.88955061\\\\\n",
        "             0.80039961\n",
        "         \\end{array}\\right)\n",
        "$\n",
        "\n",
        "The MSE is given by\n",
        "\n",
        "$\n",
        "E_{MSE} = \\Vert O-t \\Vert_2^2\n",
        "    = \\Vert\n",
        "         \\left(\\begin{array}{c}\n",
        "             0.88955061\\\\\n",
        "             0.80039961\n",
        "         \\end{array}\\right)-\n",
        "         \\left(\\begin{array}{c}\n",
        "             0.1\\\\\n",
        "             0.05\n",
        "         \\end{array}\\right)\n",
        "      \\Vert_2^2\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cv0h9O9DJ4Pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd81a07f-9fb4-48a9-9c18-0f78a464b43e"
      },
      "source": [
        "# target output\n",
        "t = np.array([0.1, 0.05])\n",
        "\n",
        "mse = np.sum(np.power(t - O, 2))\n",
        "print('MSE = {}'.format(mse))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE = 1.186489743807772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1yU4JXBhJ4Pc"
      },
      "source": [
        "So we get\n",
        "$ E_{MSE} = 1.186 $ ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbBuA0lvJ4Pc"
      },
      "source": [
        "2. Now let us perform a single backward pass and calculate the gradients. For that I will use the\n",
        "same notation as in the tutorial where we enumerate the layers and the activations as follows:\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    Z^{(0)}&=X\\\\\n",
        "    Z^{(1)}&=W_1^TZ^{(0)}+b_1\\\\\n",
        "    Z^{(2)}&=\\phi(Z^{(1)})\\color{red}{\\quad\\,\\,\\equiv h}\\\\\n",
        "    Z^{(3)}&=W_2^TZ^{(2)}+b_2\\\\\n",
        "    Z^{(4)}&=\\phi(Z^{(3)})\\color{red}{\\quad\\,\\,\\equiv O}\\\\\n",
        "    Z^{(5)}&=( Z^{(4)} - t)^2\\\\\n",
        "    Z^{(6)}&= \\sum_{i}Z^{(5)}_i\\color{red}{\\equiv E_{MSE}}\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "the numerical values at each step are\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "Z^{(0)}=\\left(\\begin{array}{c}\n",
        "            1\\\\\n",
        "            4\\\\\n",
        "            5\n",
        "        \\end{array}\\right),\\quad\n",
        "Z^{(1)}=\\left(\\begin{array}{c}\n",
        "            4.3\\\\\n",
        "            5.3\n",
        "        \\end{array}\\right),\\quad\n",
        "Z^{(2)}=\\left(\\begin{array}{c}\n",
        "            0.987\\\\\n",
        "            0.995\n",
        "        \\end{array}\\right),\\quad\n",
        "Z^{(3)}=\\left(\\begin{array}{c}\n",
        "            2.086\\\\\n",
        "            1.389\n",
        "        \\end{array}\\right),\\quad\n",
        "Z^{(4)}=\\left(\\begin{array}{c}\n",
        "            0.89\\\\\n",
        "            0.8\n",
        "        \\end{array}\\right),\\quad\n",
        "Z^{(5)}=\\left(\\begin{array}{c}\n",
        "            0.623\\\\\n",
        "            0.563\n",
        "        \\end{array}\\right),\\quad\n",
        "Z^{(6)}=1.186\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "then, we would like to calculate $\\frac{\\partial E_{MSE}}{\\partial W_l}, \\frac{\\partial E_{MSE}}{\\partial b_l}$ so we\n",
        "can later update the weights using SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "A_ypbF-8J4Pd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a30173-6a0a-4813-ca38-5180fcdf2169"
      },
      "source": [
        "# computing all Z values\n",
        "Z0 = X\n",
        "Z1 = np.transpose(W1) @ Z0 + b1\n",
        "Z2 = sigmoid(Z1)\n",
        "Z3 = np.transpose(W2) @ Z2 + b2\n",
        "Z4 = sigmoid(Z3)\n",
        "Z5 = np.power(Z4 - t, 2)\n",
        "Z6 = np.sum(Z5)\n",
        "\n",
        "print('The numerical values of each step are:')\n",
        "print('\\nZ0 = {}\\nZ1 = {}\\nZ2 = {}\\nZ3 = {}\\nZ4 = {}\\nZ5 = {}\\nZ6 = {}'.format(Z0, Z1, Z2, Z3, Z4, Z5, Z6))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The numerical values of each step are:\n",
            "\n",
            "Z0 = [1. 4. 5.]\n",
            "Z1 = [4.3 5.3]\n",
            "Z2 = [0.98661308 0.9950332 ]\n",
            "Z3 = [2.08615904 1.38879379]\n",
            "Z4 = [0.88955061 0.80039961]\n",
            "Z5 = [0.62339017 0.56309957]\n",
            "Z6 = 1.186489743807772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6mfnjMbKJ4Pd"
      },
      "source": [
        "First we compute each partial derivative term\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}}&=1\\\\\n",
        "    \\frac{\\partial Z^{(5)}}{\\partial Z^{(4)}}&=2(Z^{(4)}-t)\\\\\n",
        "    \\frac{\\partial Z^{(4)}}{\\partial Z^{(3)}}&=\\phi(Z^{(3)})(1-\\phi(Z^{(3)}))\\\\\n",
        "    \\frac{\\partial Z^{(3)}}{\\partial Z^{(2)}}&=W_2^T\\\\\n",
        "    \\frac{\\partial Z^{(3)}}{\\partial W_2}&=Z^{(2)}\\\\\n",
        "    \\frac{\\partial Z^{(3)}}{\\partial b_2}&=1\\\\\n",
        "    \\frac{\\partial Z^{(2)}}{\\partial Z^{(1)}}&=\\phi(Z^{(1)})(1-\\phi(Z^{(1)}))\\\\\n",
        "    \\frac{\\partial Z^{(1)}}{\\partial Z^{(0)}}&=W_1^T\\\\\n",
        "    \\frac{\\partial Z^{(1)}}{\\partial W_1}&=Z^{(0)}\\\\\n",
        "    \\frac{\\partial Z^{(1)}}{\\partial b_1}&=1\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "now say we would like to calculate the partial derivative of the error $E$ with respect\n",
        "to the $(1, 1)$ entry of $W^2$ which is $W^2_{11}$ (from now on we will write the number of\n",
        " the weights matrices as a superscript in order to save the subscript to matrix indices).\n",
        "So"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-nTJSjMBJ4Pe"
      },
      "source": [
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial W^2_{11}} &= \\frac{\\partial Z^{(6)}}{\\partial W^2_{11}}\\\\\n",
        "    &= \\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}_1}\\cdot\\frac{\\partial Z^{(5)}_1}{\\partial Z^{(4)}_1}\\cdot\\frac{\\partial Z^{(4)}_1}{\\partial Z^{(3)}_1}\\cdot\\frac{\\partial Z^{(3)}_1}{\\partial W^2_{11}}\\\\\n",
        "    &= 1\\cdot 2(Z^{(4)}_1 - t)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot\\frac{\\partial }{\\partial W^2_{11}}(W^2_{11}Z^{(2)}_1+W^2_{21}Z^{(2)}_2+b^2_1)\\\\\n",
        "    &= 1\\cdot 2(Z^{(4)}_1 - t)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot Z^{(2)}_1\\\\\n",
        "    &= 1\\cdot 1.57910123\\cdot 0.09825032\\cdot 0.987\\\\\n",
        "    &= 0.15307026\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "in the same way\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial W^2_{21}} &= \\frac{\\partial Z^{(6)}}{\\partial W^2_{21}}\\\\\n",
        "    &= \\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}_1}\\cdot\\frac{\\partial Z^{(5)}_1}{\\partial Z^{(4)}_1}\\cdot\\frac{\\partial Z^{(4)}_1}{\\partial Z^{(3)}_1}\\cdot\\frac{\\partial Z^{(3)}_1}{\\partial W^2_{21}}\\\\\n",
        "    &= 1\\cdot 2(Z^{(4)}_1 - t)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot\\frac{\\partial }{\\partial W^2_{11}}(W^2_{11}Z^{(2)}_1+W^2_{21}Z^{(2)}_2+b^2_1)\\\\\n",
        "    &= 1\\cdot 2(Z^{(4)}_1 - t)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot Z^{(2)}_2\\\\\n",
        "    &= 1\\cdot 1.57910123\\cdot 0.09825032\\cdot 0.995\\\\\n",
        "    &= 0.15437661\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "and\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial b^2_{1}} &= \\frac{\\partial Z^{(6)}}{\\partial b^2_{1}}\\\\\n",
        "    &= \\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}_1}\\cdot\\frac{\\partial Z^{(5)}_1}{\\partial Z^{(4)}_1}\\cdot\\frac{\\partial Z^{(4)}_1}{\\partial Z^{(3)}_1}\\cdot\\frac{\\partial Z^{(3)}_1}{\\partial b^2_{1}}\\\\\n",
        "    &= 1\\cdot 2(Z^{(4)}_1 - t)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot\\frac{\\partial }{\\partial W^2_{11}}(W^2_{11}Z^{(2)}_1+W^2_{21}Z^{(2)}_2+b^2_1)\\\\\n",
        "    &= 1\\cdot 2(Z^{(4)}_1 - t)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot 1\\\\\n",
        "    &= 1\\cdot 1.57910123\\cdot 0.09825032\\cdot 1\\\\\n",
        "    &= 0.1551472\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "The other derivatives of $E$ with respect to $W^2_{12}, W^2_{22}, b^2_{2}$ are\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial W^2_{12}} &=1\\cdot 2(Z^{(4)}_2 - t)\\cdot \\phi(Z^{(3)}_2)(1-\\phi(Z^{(3)}_2))\\cdot Z^{(2)}_1=0.236558\\\\\n",
        "    \\frac{\\partial E}{\\partial W^2_{22}} &=1\\cdot 2(Z^{(4)}_2 - t)\\cdot \\phi(Z^{(3)}_2)(1-\\phi(Z^{(3)}_2))\\cdot Z^{(2)}_2=0.238577\\\\\n",
        "    \\frac{\\partial E}{\\partial b^2_{2}} &=1\\cdot 2(Z^{(4)}_2 - t)\\cdot \\phi(Z^{(3)}_2)(1-\\phi(Z^{(3)}_2))\\cdot 1=0.239768\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Following similar steps lets calculate the derivatives of $E$ with respect to $W^1_{ij}, b^1_{ij}$\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "   \\frac{\\partial E}{\\partial W^1_{11}} &= \\frac{\\partial Z^{(6)}}{\\partial W^1_{11}}\\\\\n",
        "    &= \\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}}\\cdot\\frac{\\partial Z^{(5)}}{\\partial Z^{(4)}}\\cdot\\frac{\\partial Z^{(4)}}{\\partial Z^{(3)}}\\cdot\\frac{\\partial Z^{(3)}}{\\partial Z^{(2)}}\\cdot\\frac{\\partial Z^{(2)}}{\\partial Z^{(1)}}\\cdot\\frac{\\partial Z^{(1)}}{\\partial W^1_{11}}\\\\\n",
        "    &= \\left(\\color{red}{\\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}_1}\\cdot\\frac{\\partial Z^{(5)}_1}{\\partial Z^{(4)}_1}\\cdot\\frac{\\partial Z^{(4)}_1}{\\partial Z^{(3)}_1}\\cdot\\frac{\\partial Z^{(3)}_1}{\\partial Z^{(2)}_1}} +\n",
        "    \\color{green}{\\frac{\\partial Z^{(6)}}{\\partial Z^{(5)}_2}\\cdot\\frac{\\partial Z^{(5)}_2}{\\partial Z^{(4)}_2}\\cdot\\frac{\\partial Z^{(4)}_2}{\\partial Z^{(3)}_2}\\cdot\\frac{\\partial Z^{(3)}_2}{\\partial Z^{(2)}_1}}\\right)\n",
        "    \\cdot\\left(\\color{#F4C430}{\\frac{\\partial Z^{(2)}_1}{\\partial Z^{(1)}_1}\\cdot\\frac{\\partial Z^{(1)}_1}{\\partial W^1_{11}}}\\right)\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Notice that there should be more terms in the derivation above, but I ignored all the terms\n",
        " which are zero, i.e. $\\frac{\\partial Z^{(4)}_1}{\\partial Z^{(3)}_2}$ because they have no contribution.\n",
        "\n",
        "Also, in the derivation above I colored the terms in a compatible way to the figure below for it would be easier to read.\n",
        "Each singly colored bulk of terms corresponds to the computation in the reverse direction of the line with the same color.\n",
        "\n",
        "Finally, by inserting numerical values inplace of symbolic terms we get\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial W^1_{11}} &= \\left(\\color{red}{1\\cdot 2(Z^{(4)}_1-t_1)\\cdot \\phi(Z^{(3)}_1)(1-\\phi(Z^{(3)}_1))\\cdot W^2_{11}} +\n",
        "    \\color{green}{1\\cdot 2(Z^{(4)}_2-t_2)\\cdot \\phi(Z^{(3)}_2)(1-\\phi(Z^{(3)}_2))\\cdot W^2_{12}}\\right)\n",
        "    \\cdot\\left(\\color{#F4C430}{\\phi(Z^{(1)}_1)(1-\\phi(Z^{(1)}_1))\\cdot Z^{(0)}_1}\\right)\\\\\n",
        "     &= \\left(\\color{red}{1\\cdot 1.57910123\\cdot 0.09825032\\cdot 0.7} +\n",
        "    \\color{green}{1\\cdot 1.50079922\\cdot 0.15976008\\cdot 0.8}\\right)\n",
        "    \\cdot\\left(\\color{#F4C430}{0.01320771\\cdot 1}\\right)\\\\\n",
        "    &= 0.003967824\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "Exactly in the same way we can compute all other derivatives of $E$ with respect to $W^1_{ij}, b^1_{ij}$. But, because\n",
        "it will take a lot of time I won't write the computation explicitly but only\n",
        "the final results. So\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial W^1} &= \\left(\\begin{array}{cc} 0.00396782 & 0.00080858\\\\0.01587129 & 0.00323431\\\\ 0.01983912 & 0.00404289\\\\\\end{array}\\right)\\\\\\\\\n",
        "    \\frac{\\partial E}{\\partial b^1} &= \\left(\\begin{array}{c} 0.00396782 & 0.00080858 \\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "while the derivatives with respect to $W^2$ and $b^2$ are\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    \\frac{\\partial E}{\\partial W^2} &= \\left(\\begin{array}{cc} 0.15307026 & 0.23655804\\\\ 0.15437661 & 0.23857692\\\\\\end{array}\\right)\\\\\\\\\n",
        "    \\frac{\\partial E}{\\partial b^2} &= \\left(\\begin{array}{c} 0.1551472 & 0.2397678 \\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "and we are done with this part. Next we need to cacluate a single SGD step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gphnPwxQXf03"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/RoyElkabetz/EE-046211---Technion---Deep-Learning/main/Hw2/hw2_q2_net.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "utM0jcc2J4Pf"
      },
      "source": [
        "# numerical values of all local terms\n",
        "dZ6dZ5 = np.ones(2)\n",
        "dZ5dZ4 = 2*(Z4-t)\n",
        "dZ4dZ3 = sigmoid(Z3) * (1 - sigmoid(Z3))\n",
        "dZ3dZ2 = np.transpose(W2)\n",
        "dZ3dW2 = Z2\n",
        "dZ3db2 = np.ones(2)\n",
        "dZ2dZ1 = sigmoid(Z1) * (1 - sigmoid(Z1))\n",
        "dZ1dZ0 = np.transpose(W1)\n",
        "dZ1dW1 = Z0\n",
        "dZ1db1 = np.ones(2)\n",
        "\n",
        "print('ALL THE LOCAL PARTIAL DERIVATIVES ARE:')\n",
        "print('\\ndZ6/dZ5 = \\n',dZ6dZ5)\n",
        "print('\\ndZ5/dZ4 = \\n',dZ5dZ4)\n",
        "print('\\ndZ4/dZ3 = \\n',dZ4dZ3)\n",
        "print('\\ndZ3/dZ2 = \\n',dZ3dZ2)\n",
        "print('\\ndZ3/dW2 = \\n',dZ3dW2)\n",
        "print('\\ndZ3/db2 = \\n',dZ3db2)\n",
        "print('\\ndZ2/dZ1 = \\n',dZ2dZ1)\n",
        "print('\\ndZ1/dZ0 = \\n',dZ1dZ0)\n",
        "print('\\ndZ1/dW1 = \\n',dZ1dW1)\n",
        "print('\\ndZ1/db1 = \\n',dZ1db1)\n",
        "\n",
        "# calculating dE/dW2, dE/dB2 manually for conformation\n",
        "dEdW211 = dZ6dZ5[0] * dZ5dZ4[0] * dZ4dZ3[0] * dZ3dW2[0]\n",
        "dEdW221 = dZ6dZ5[0] * dZ5dZ4[0] * dZ4dZ3[0] * dZ3dW2[1]\n",
        "dEdb21 = dZ6dZ5[0] * dZ5dZ4[0] * dZ4dZ3[0] * dZ3db2[0]\n",
        "\n",
        "dEdW212 = dZ6dZ5[1] * dZ5dZ4[1] * dZ4dZ3[1] * dZ3dW2[0]\n",
        "dEdW222 = dZ6dZ5[1] * dZ5dZ4[1] * dZ4dZ3[1] * dZ3dW2[1]\n",
        "dEdb22 = dZ6dZ5[1] * dZ5dZ4[1] * dZ4dZ3[1] * dZ3db2[1]\n",
        "\n",
        "# calculating dE/dW2, dE/dB2 in a vectorcall way\n",
        "dEdW2 = np.reshape(dZ6dZ5 * dZ5dZ4 * dZ4dZ3, (2, -1)) * np.reshape(dZ3dW2, (-1, 2))\n",
        "dEdb2 = dZ6dZ5 * dZ5dZ4 * dZ4dZ3 * dZ3db2\n",
        "\n",
        "print('\\n')\n",
        "print('dE/dW2{11} = ',dEdW211)\n",
        "print('dE/dW2{21} = ',dEdW221)\n",
        "print('dE/db2{1} = ',dEdb21)\n",
        "print('dE/dW2{12} = ',dEdW212)\n",
        "print('dE/dW2{22} = ',dEdW222)\n",
        "print('dE/db2{2} = ',dEdb22)\n",
        "\n",
        "print('\\ndE/dW2 = \\n',dEdW2)\n",
        "print('\\ndE/db2 = \\n',dEdb2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Q2HqqXcUJ4Pg"
      },
      "source": [
        "# calculating two derivatives manually (just for conformation)\n",
        "dEdW111 = (dZ6dZ5[0] * dZ5dZ4[0] * dZ4dZ3[0] * dZ3dZ2[0, 0] +\n",
        "           dZ6dZ5[1] * dZ5dZ4[1] * dZ4dZ3[1] * dZ3dZ2[1, 0]) * \\\n",
        "          (dZ2dZ1[0] * dZ1dW1[0])\n",
        "print('\\n dE/dW1{11} = ',dEdW111)\n",
        "\n",
        "dEdW121 = (dZ6dZ5[0] * dZ5dZ4[0] * dZ4dZ3[0] * dZ3dZ2[0, 0] +\n",
        "           dZ6dZ5[1] * dZ5dZ4[1] * dZ4dZ3[1] * dZ3dZ2[1, 0]) * \\\n",
        "          (dZ2dZ1[0] * dZ1dW1[1])\n",
        "print('\\n dE/dW1{21} = ',dEdW121)\n",
        "\n",
        "# calculating dE/dW1, dE/db1 in a vectorcall way\n",
        "dEdZ2 = dZ4dZ3 * dZ5dZ4 * dZ6dZ5 @ dZ3dZ2\n",
        "dEdW1 = np.reshape(dEdZ2 * dZ2dZ1, (2, -1)) * np.reshape(dZ1dW1, (-1, 3))\n",
        "dEdb1 = (dZ4dZ3 * dZ5dZ4 * dZ6dZ5 @ dZ3dZ2) * dZ2dZ1 * dZ1db1\n",
        "\n",
        "print('\\ndE/dZ2 = \\n', dEdZ2)\n",
        "print('\\ndE/dW1 = \\n', dEdW1)\n",
        "print('\\ndE/db1 = \\n', dEdb1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "zw9HLv-uJ4Pg"
      },
      "source": [
        "3. For learning rate $\\alpha = 0.01$ let us compute the new weights with a single SGD step following\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    W_{(step = 1)} = W_{(step = 0)} - \\alpha\\nabla_W E(X,t)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "so\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    W_{(step = 1)}^1 &= W_{(step = 0)}^1 - \\alpha \\frac{\\partial E(X,t)}{\\partial W^1} = \\left(\\begin{array}{cc} 0.09996032 &0.19999191\\\\0.29984129 &0.39996766\\\\ 0.49980161 &0.59995957\\\\\\end{array}\\right)\\\\\\\\\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "and\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    b_{(step = 1)}^1 &= b_{(step = 0)}^1 - \\alpha \\frac{\\partial E(X,t)}{\\partial b^1}\n",
        "                     =  \\left(\\begin{array}{c} 0.49996032 \\\\0.49999191\\\\\\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "and\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    W_{(step = 1)}^2 &= W_{(step = 0)}^2 - \\alpha \\frac{\\partial E(X,t)}{\\partial W^2}\n",
        "                     =  \\left(\\begin{array}{cc} 0.6984693 & 0.79763442\\\\ 0.89845623 & 0.09761423\\\\\\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "and finally\n",
        "\n",
        "$\n",
        "\\begin{align}\n",
        "    b_{(step = 1)}^2 &= b_{(step = 0)}^2 - \\alpha \\frac{\\partial E(X,t)}{\\partial b^2}\n",
        "                     =  \\left(\\begin{array}{c} 0.49844853 \\\\0.49760232\\\\\\end{array}\\right)\n",
        "\\end{align}\n",
        "$\n",
        "\n",
        "and we are done with this horror."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NA2OuIq9J4Pg"
      },
      "source": [
        "lr = 0.01\n",
        "\n",
        "# calculating a single SGD step\n",
        "W1_new = W1 - lr * np.transpose(dEdW1)\n",
        "W2_new = W2 - lr * np.transpose(dEdW2)\n",
        "b1_new = b1 - lr * np.transpose(dEdb1)\n",
        "b2_new = b2 - lr * np.transpose(dEdb2)\n",
        "\n",
        "print('\\nW1_new = \\n', W1_new)\n",
        "print('\\nb1_new = \\n', b1_new)\n",
        "print('\\nW2_new = \\n', W2_new)\n",
        "print('\\nb2_new = \\n', b2_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SPk-Wq_J4Ph"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 3 - Deep Double Descent\n",
        "---\n",
        "\n",
        "For the following plots:\n",
        "1. Where is the critical point (the point of transition between the \"Classical Regime\" and \"Modern Regime\") of the deep double descent?\n",
        "2. What type of double descent is shown? Explain.\n",
        "    \n",
        "\n",
        "a. <img src='https://raw.githubusercontent.com/taldatech/ee046211-deep-learning/main/assets/double_descent_transformer.PNG' style=\"height:300px\">\n",
        "\n",
        "b. <img src='https://raw.githubusercontent.com/taldatech/ee046211-deep-learning/main/assets/double_descent_resnet.PNG' style=\"height:300px\">\n",
        "\n",
        "c. <img src='https://raw.githubusercontent.com/taldatech/ee046211-deep-learning/main/assets/double_descent_intermediate.PNG' style=\"height:300px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "5x0s9DwhJ4Ph"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 3 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "1.\n",
        "\n",
        "a. The critical point in that case would be the point where the test error reaches its maximum value\n",
        "which is at model size of approximately 200 for De-En and approximatly 290 for En-Fr.\n",
        "\n",
        "b. In that case there are three critical points, one for each label noise percentage:\n",
        "At 0% label noise the critical point is at a width parameter of 10 (where the test reaches its maximum),\n",
        "for 10% label noise the critical point is at around width parameter of 12 and for 20% label noise its around a width\n",
        "parameter of 14.\n",
        "\n",
        "c. In that case we also have three different models, but this time test error is plot vs\n",
        "the number of training epochs. We see that for small model the test error did not reach the\n",
        "critical point. This is because the error is monotonically decreasing along the entire training process\n",
        "so it is still in the classical regime. For an intermidiate model the critical point is around 1k epochs,\n",
        "while for the large model the test error reaches a critical point around 80 epochs.\n",
        "\n",
        "2.\n",
        "\n",
        "a. In that case we can see that for both datasets, De-En and En-Fr, the double decent type\n",
        "is a \"model-wise\" double decent because the behavior depends on the model embedding dimension (model size).\n",
        "\n",
        "b. In that case the double decent type is some kind of \"sample wise\" double decent, although\n",
        "it does not vary with the size of the training set, but it surly depends on the amount of\n",
        "good training data, where we see that cleaner dataset (less noise) results in a smaller test error in the critical\n",
        "double decent region.\n",
        "\n",
        "c.\n",
        "In the lase case we got an \"epoch wise\" double decent type where the critical region\n",
        "is pushed later in the training process for smaller and smaller models, as we have seen in the\n",
        "tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vusmbi8rJ4Ph"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 4 - Initialization\n",
        "---\n",
        "\n",
        "Recall that in lecture 5 we were discussing how to calculate the initialization variance, and reached the conclusion that $$ \\sigma_l =\\frac{1}{\\sqrt{d_{l-1}\\mathbb{E}_{z\\sim \\mathcal{N}(0, 1)} \\left[\\varphi^2(z)\\right]}} $$\n",
        "Show that for ReLU activation ($\\varphi(z) = max(0,z)$), the optimal variance satisfies: $$ \\sigma_l = \\sqrt{\\frac{2}{d_{l-1}}}$$\n",
        "\n",
        "All the notations are the same as in the lecture slides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pofTgorjl6ZL"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 4 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "We calculate\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\mathbb{E}_{z\\sim \\mathcal{N}(0, 1)}\\left[\\varphi^2(z)\\right] &= \\int_{-\\infty}^{\\infty}\\max\\lbrace 0, z\\rbrace^2 \\frac{1}{\\sqrt{2\\pi}}\\exp{\\left(-\\frac{z^2}{2}\\right)}dz\\\\\n",
        "  &= \\int_{0}^{\\infty}z^2 \\frac{1}{\\sqrt{2\\pi}}\\exp{\\left(-\\frac{z^2}{2}\\right)}dz\\\\\n",
        "  &= \\frac{1}{2}\\int_{-\\infty}^{\\infty}z^2 \\frac{1}{\\sqrt{2\\pi}}\\exp{\\left(-\\frac{z^2}{2}\\right)}dz\\\\\n",
        "  &= \\frac{1}{2}\\mathbb{E}_{z\\sim \\mathcal{N}(0, 1)}\\left[z^2\\right]\\\\\n",
        "  &= \\frac{1}{2}\\left(\\text{Var}_{z\\sim \\mathcal{N}(0, 1)}(z)-\\mathbb{E}_{z\\sim \\mathcal{N}(0, 1)}\\left[z\\right]^2\\right)\\\\\n",
        "  &= \\frac{1}{2}\\left(1-0\\right)\\\\\n",
        "  &= \\frac{1}{2}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "placing this result back into the $\\sigma_l$ relation above we get\n",
        "\n",
        "$$ \\sigma_l = \\sqrt{\\frac{2}{d_{l-1}}}$$\n",
        "\n",
        "and we are done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNdQv8RJ4Pj"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 5 -Equivarinace\n",
        "---\n",
        "\n",
        "Recall from lecture 6:\n",
        "A function $f: \\mathcal{R}^d \\to \\mathcal{R}$ is equivariant if $f(\\tau \\cdot x) = \\tau \\cdot f(x)$ for all $\\tau$.\n",
        "\n",
        "Let $f_w(x) = \\phi (Wx)$ where $\\phi$ is a component-wise non-linearity and $W \\in \\mathcal{R}^{d\\times d}$. Prove that $f_w:\\mathcal{R}^d \\to \\mathcal{R}^d$ is equivariant to transformation family $H$ **if and only if**: $$ \\forall \\tau \\in H, W[i, j] = W[\\tau(i), \\tau(j)] $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaZMB1UMGmsc"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 5 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "\n",
        "**First direction:**\n",
        "\n",
        "Say $$ \\forall \\tau \\in H, W[i, j] = W[\\tau(i), \\tau(j)] $$\n",
        "So $\\tau$ is a transformation that satisfies the next relation $$\\tau^{-1} W \\tau=W$$\n",
        "Then \n",
        "\n",
        "\\begin{align}\n",
        "  f_w\\left(\\tau x\\right) &= \\phi\\left(W(\\tau x)\\right)\\\\\n",
        "   &= \\phi\\left(IW(\\tau x)\\right)\\\\\n",
        "   &= \\phi\\left(\\tau \\tau^{-1}W(\\tau x)\\right)\\\\\n",
        "   &= \\phi\\left(\\tau \\left(\\tau^{-1}W\\tau\\right) x\\right)\\\\\n",
        "   &= \\phi\\left(\\tau W x\\right)\\\\\n",
        "   &= \\tau f_{ w}\\left( x\\right)\n",
        "\\end{align}\n",
        "\n",
        "where in the last line we used the fact that $\\phi$ is an entrywise operator.\n",
        "\n",
        "**Second direction:**\n",
        "Say $f_w=\\phi\\left(Wx\\right)$ is equivariante, so $\\forall \\tau$ $$f_w(\\tau x)=\\tau f_{ w}( x)$$\n",
        "\n",
        "Notice that \n",
        "\\begin{align}\n",
        "  f_w\\left(\\tau x\\right) &= \\phi\\left(W(\\tau x)\\right)\\\\\n",
        "   &= \\phi\\left(IW(\\tau x)\\right)\\\\\n",
        "   &= \\phi\\left(\\tau \\tau^{-1}W(\\tau x)\\right)\\\\\n",
        "   &= \\phi\\left(\\tau \\left(\\tau^{-1}W\\tau\\right) x\\right)\n",
        "\\end{align}\n",
        "\n",
        "while also\n",
        "\\begin{align}\n",
        " \\tau f_{ w}\\left(x\\right) &= \\tau\\phi\\left( W x\\right)\\\\\n",
        " &= \\phi\\left(\\tau W x\\right)\n",
        "\\end{align}\n",
        "\n",
        "so we get that\n",
        "\\begin{align}\n",
        "  \\phi\\left(\\tau \\left(\\tau^{-1}W\\tau\\right) x\\right) &= \\phi\\left(\\tau W x\\right)\\\\\n",
        "\\end{align}\n",
        "\n",
        "which implies\n",
        "$$\\tau^{-1}W\\tau =  W$$\n",
        "\n",
        "and we are done\n",
        "\n",
        "<div style=\"text-align: right\"> $\\color{#4CBB17}{\\rule{1.7ex}{1.7ex}}$ </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs2yLCpCJ4Pk"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 6 -VGG Architecture\n",
        "---\n",
        "\n",
        "1. The VGG-11 CNN architecture consists of 11 convolution (CONV)/fully-connected (FC) layers (every CONV layer has the same padding and stride, every MAXPOOL layer is 22 and has padding of 0 and stride 2). Fill in the table. You need to **consider the bias**.\n",
        "\n",
        "\n",
        "* CONV$M$-$N$: a convolutional layer with $N$ neurons, each of size $M \\times M \\times D$, where $D$ is the number of filters. $stride=1, padding=2$ \n",
        "* POOL2: $2 \\times 2$ Max Pooling with $stride=2$\n",
        "    * In case the input of the layer is odd, you should round down. For example, if the output of the layer should be $3.5 \\times 3.5 \\times 3$, you should round to $3 \\times 3 \\times 3$ (i.e., ignore the last column of the input image when performing MaxPooling).\n",
        "* FC-N: a fully connected layer with $N$ neurons.\n",
        "\n",
        "\n",
        "| Layer  | Output Dimension  | Number of Parameters (Weights) |\n",
        "|---|---|---|\n",
        "| INPUT     |  224x224x3   | 0                           |\n",
        "|  CONV3-64 | 224x224x64   | 3x3x3x64+64=1792            |  \n",
        "| ReLU      |  224x224x64  | 0                           |\n",
        "| POOL2     |  112x112x64  | 0                           |\n",
        "|CONV3-128  | 112x112x128  | 3x3x64x128+128=73856        |\n",
        "|ReLU       | 112x112x128  | 0                           |\n",
        "| POOL2     |  56x56x128   | 0                           |\n",
        "|CONV3-256  | 56x56x256    | 3x3x128x256+256 = 295168    |\n",
        "|ReLU       | 56x56x256    | 0                           |\n",
        "|CONV3-256  | 56x56x256    | 3x3x256x256+256 = 590080    |\n",
        "|ReLU       | 56x56x256    | 0                           |\n",
        "| POOL2     |  28x28x256   | 0                           |\n",
        "|CONV3-512  | 28x28x512    | 3x3x256x512+512 = 1180160   |\n",
        "|ReLU       | 28x28x512    | 0                           |\n",
        "|CONV3-512  | 28x28x512    | 3x3x512x512+512 = 2359808   |\n",
        "|ReLU       | 28x28x512    | 0                           |\n",
        "| POOL2     |  14x14x512   | 0                           |\n",
        "|CONV3-512  | 14x14x512    | 3x3x512x512+512 = 2359808   |\n",
        "|ReLU       | 14x14x512    | 0                           |\n",
        "|CONV3-512  | 14x14x512    | 3x3x512x512+512 = 2359808   |\n",
        "|ReLU       | 14x14x512    | 0                           |\n",
        "| POOL2     |  7x7x512     | 3x3x512x512+512 = 2359808   |\n",
        "| FC-4096   |  1x4096      | 7x7x512x4096+4096 = 102764544  |\n",
        "| FC-4096   |  1x4096      | 4096x4096+4096 = 16781312   |\n",
        "| FC-1000   |  1x1000      | 4096x1000+1000 = 4097000    |\n",
        "| SOFTMAX   |  1x10        | 1000x10+10 = 10010          |\n",
        "\n",
        "2. What is the total number of parameters? (use a calculator for this one)\n",
        "3. What percentage of the weights are found in the fully-connected layers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgVF5DcNkXfn"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/26e07f/about.png\" style=\"height:50px;display:inline\">Question 6 - <span style=\"color: HotPink\">Solution</span>\n",
        "---\n",
        "\n",
        "2. The total number of parameters is 132873346.\n",
        "\n",
        "3. The percentage of weights fuond in all fc layers from the total amount is $93.06$%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFGL2ExzjXo5"
      },
      "source": [
        "total_num_weights = 1792 + 73856 + 295168 + 590080 + 1180160 + 2359808 + 2359808 + 2359808 + 102764544 + 16781312 + 4097000 + 10010\n",
        "print('total number of parameters: ',total_num_weights)\n",
        "fc_num_weights = 102764544 + 16781312 + 4097000 + 10010\n",
        "print('total number of parameters in fc layers: ',fc_num_weights)\n",
        "print('percentage of fc parameters from total: ',fc_num_weights / total_num_weights * 100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-14iM7pGhm"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/officel/80/000000/code.png\" style=\"height:50px;display:inline\"> Part 2 - Code Assignments\n",
        "---\n",
        "* You must write your code in this notebook and save it with the output of all of the code cells.\n",
        "* Additional text can be added in Markdown cells.\n",
        "* You can use any other IDE you like (PyCharm, VSCode...) to write/debug your code, but for the submission you must copy it to this notebook, run the code and save the notebook with the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4XNY-o7J4Pk"
      },
      "source": [
        "#### Tips\n",
        "---\n",
        "1. Uniformly distributed tensors - `torch.Tensor(dim1, dim2, ...,dimN).uniform_(-1, 1)`\n",
        "2. Separation to **validation set** in PyTorch - <a href=\"https://gist.github.com/MattKleinsmith/5226a94bad5dd12ed0b871aed98cb123\">See example here</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m8OkOHWJ4Pl"
      },
      "source": [
        "!pip install torchviz\n",
        "\n",
        "# imports for the practice (you can add more if you need)\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib notebook\n",
        "%matplotlib inline\n",
        "\n",
        "seed = 211\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBsG_pPIJ4Pl"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 1 - The Importance of Activation and Initialization\n",
        "---\n",
        "In this task, we are going to use $x \\in \\mathcal{R}^{512}$ and simple neural network that outputs $f(x) \\in \\mathcal{R}^{512}$. The network will have 100 layers with 512 units in each layer.\n",
        "\n",
        "1. We initialize the weights from a unit normal distribution. Run the following code cell and explain what happens. Add a short piece of code that locates when it happens (hint: use `torch.isnan()`). **Print** the layer number.\n",
        "2. We can demonstrate that at a given layer, the matrix product of inputs $x$ and weight matrix $a$ that is initialized from a standard normal distribution will, on average, have a standard deviation very close to the square root of the number of input connections. For our example, with 512 dimensions, show that for 10,000 multiplications of $a$ and $x$, the empirical standard deviation is similar to the square root of the number of input connections. Use the unbiased version: $$ \\hat{std} = \\sqrt{\\frac{\\sum_{i=1}^{10000}\\frac{1}{N}\\sum_{j=1}^N y^2}{10000}}, $$ where $y=ax$ and $N$ is the number of input connections. **Print** the mean, std and the square root of the number of input connections.\n",
        "3. For the code from 1, normalize the weight initialization by the square root of the input connections. How does that change the outcome? **Print** the mean and std after the modification.\n",
        "4. Add a `tanh()` activation after each layer for the code from 1. **Print** the mean and std after the modification. Explain the result.\n",
        "5. Xavier initialization sets a layers weights to values chosen from a random uniform distribution thats bounded between $$\\pm \\sqrt{\\frac{6}{n_i + n_{i+1}}}$$ where $n_i$ is the number of incoming network connections, or fan-in, to the layer, and $ n_{i+1}$ is the number of outgoing network connections from that layer, also known as the fan-out. Glorot and Bengio believed that Xavier weight initialization would maintain the variance of activations and back-propagated gradients all the way up or down the layers of a network and demonstrated that networks initialized with Xavier achieved substantially quicker convergence and higher accuracy. Implement **Xavier Uniform** as `xavier_init(fan_in, fan_out)`, a function that returns a tensor initialized according to **Xavier Uniform**. Use it on the simple network from 1 with `tanh` activation. **Print** the mean and std after the modification.\n",
        "6. If you try to replace the `tanh` activation with `relu` activation in section 5, you will see very different results. Xavier strives to acheive activation outputs of each layer to have a mean of 0 and a standard deviation around 1, on average. When using a ReLU activation, a single layer will, on average have standard deviation thats very close to the square root of the number of input connections, **divided by the square root of two** ($\\sqrt{\\frac{512}{2}}$ in our example). **Kaiming He et. al.** proposed an initialization scheme thats tailored for deep neural nets that use these kinds of asymmetric, non-linear activations. Implement **Kaiming Normal** as `kaiming_init(fan_in, fan_out)`, a function that returns a tensor initialized according to **Kaiming Normal** (use `fan_in` mode). Use it on the simple network from 1 with `relu` activation. **Print** the mean and std after the modification. What happens when you use Xavier with RelU activation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YafBVOoGJ4Pl"
      },
      "source": [
        "x = torch.randn(512)\n",
        "for i in range(100):\n",
        "    a = torch.randn(512, 512)\n",
        "    x = a @ x\n",
        "    # added code for visualizing the blow up effect\n",
        "    if i == 26:\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "    if torch.isnan(x.mean()) or torch.isnan(x.std()):\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "print(x.mean(), x.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHt8z1iNJ4Pm"
      },
      "source": [
        "1. We see that if we initialize the weights using a unit normal distribution, the forward pass blows up very early in the process. In the case here, it happens at layer 27, where both the mean and std of x are nans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZautwznGJ4Pm"
      },
      "source": [
        "N = 512\n",
        "m = 10000\n",
        "std_empirical = 0\n",
        "y_std = []\n",
        "y_mean = []\n",
        "\n",
        "for i in range(m):\n",
        "    x = torch.randn(N)\n",
        "    a = torch.randn(N, N)\n",
        "    y = a @ x\n",
        "    y_mean.append(y.mean())\n",
        "    y_std.append(y.std())\n",
        "    std_empirical = std_empirical + torch.sum(torch.pow(y, 2)) / N\n",
        "\n",
        "std_empirical = np.sqrt(std_empirical / m)\n",
        "print('sqrt(512): {}'.format(np.sqrt(N)))\n",
        "print('The empirical std is: {}'.format(std_empirical))\n",
        "print('The average mean of y is: {}'.format(np.mean(y_mean)))\n",
        "print('The average std of y is: {}'.format(np.mean(y_std)))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX2nM2Pb1OjQ"
      },
      "source": [
        "2. We see that the empirical std of $y$ and the average std of $y$ are both $\\approx\\sqrt{512}$.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3-HJX4_11hx"
      },
      "source": [
        "x = torch.randn(512)\n",
        "std = []\n",
        "mean = []\n",
        "for i in range(100):\n",
        "    a = torch.randn(512, 512)\n",
        "    x = a @ x / np.sqrt(512)\n",
        "    mean.append(x.mean().item())\n",
        "    std.append(x.std().item())\n",
        "    # added code for visualizing the blow up effect\n",
        "    if i == 26:\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "    if torch.isnan(x.mean()) or torch.isnan(x.std()):\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "print(x.mean(), x.std())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(100), mean, label='x.mean')\n",
        "plt.plot(range(100), std, label='x.std')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4-5gLam3JeV"
      },
      "source": [
        "3. We see that if we normalize the vector after each layer with the $\\sqrt{\\text{# units}}$, the mean and std values of $x$ do not blow up and stays very close to the initial standard distribution parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv0OLOX-3rKy"
      },
      "source": [
        "N = 512\n",
        "m = 100\n",
        "x = torch.randn(N)\n",
        "std = []\n",
        "mean = []\n",
        "std_before_tanh = []\n",
        "mean_before_tanh = []\n",
        "\n",
        "for i in range(m):\n",
        "    a = torch.randn(N, N)\n",
        "    x = a @ x\n",
        "    mean_before_tanh.append(x.mean().item())\n",
        "    std_before_tanh.append(x.std().item())\n",
        "    x = torch.tanh(x)\n",
        "    mean.append(x.mean().item())\n",
        "    std.append(x.std().item())\n",
        "    # added code for visualizing the blow up effect\n",
        "    if i == 26:\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "    if torch.isnan(x.mean()) or torch.isnan(x.std()):\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "print(x.mean(), x.std())\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "ax[0].set_title('The mean and std of $x$ before $tanh$ operation')\n",
        "ax[0].plot(range(m), mean_before_tanh, label='x.mean', color='green')\n",
        "ax[0].plot(range(m), std_before_tanh, label='x.std', color='purple')\n",
        "ax[0].axhline(np.sqrt(N), label='$\\sqrt{512}$', color='red')\n",
        "ax[0].set_ylabel('Value')\n",
        "ax[0].legend(loc='center right')\n",
        "ax[0].set_xlabel('Iteration')\n",
        "ax[0].grid()\n",
        "\n",
        "ax[1].set_title('The mean and std of $x$ after $tanh$ operation')\n",
        "ax[1].plot(range(m), mean, label='tanh(x).mean')\n",
        "ax[1].plot(range(m), std, label='tanh(x).std')\n",
        "ax[1].set_xlabel('Iteration')\n",
        "ax[1].set_ylabel('Value')\n",
        "ax[1].legend(loc='center left')\n",
        "ax[1].grid()\n",
        "\n",
        "t = np.linspace(-50, 50, 1000)\n",
        "ax[2].set_title('$tanh$ plot')\n",
        "ax[2].plot(t, np.tanh(t), label='tanh(t)')\n",
        "ax[2].scatter(np.sqrt(N),np.tanh(np.sqrt(N)), label='tanh(sqrt(512))', color='red')\n",
        "ax[2].set_xlabel('t')\n",
        "ax[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ntu7bXf4-R_"
      },
      "source": [
        "4. The $tanh(x)$ activation at each iteration maps the values of $x$ back into the $(-1, 1)$ domain. Therfore, the mean and std of $x$ do not blow up. Notice that the std of $x$ at each iteration (before the performence of the $tanh$ activation) is around $\\sqrt{512}$ (where $512$ is the number of units at $x$). After the performence of $tanh$ the values of $x$ maps very close to $\\lbrace -1, 1\\rbrace$ \"at the edge of $tanh(x)$\" because $$tanh(\\pm\\sqrt{512})\\approx \\pm 1$$ as you can see in the right plot above. Therefore, for $x\\to\\pm\\sqrt{512})$ we get $\\mathbb{E}[\\tanh{(x)}]=0$ and \n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "  \\sigma[\\tanh{(x)}] &= \\sqrt{\\mathbb{E}[\\tanh{(x)}^2]-(\\mathbb{E}[\\tanh{(x)}])^2}\\\\\n",
        "            &= \\sqrt{\\mathbb{E}[1]-0}\\\\\n",
        "            &= 1\n",
        "\\end{align}\n",
        "$$\n",
        "as we can see in the middle plot above. Notice that the because $-\\sqrt{512} < x <\\sqrt{512}$ and not equel, we get that $\\sigma[\\tanh{(x)}]$ is a bit smaller than $1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9YN3dwDFMiF"
      },
      "source": [
        "N = 512\n",
        "m = 100\n",
        "x = torch.randn(N)\n",
        "std = []\n",
        "mean = []\n",
        "std_before_tanh = []\n",
        "mean_before_tanh = []\n",
        "\n",
        "for i in range(m):\n",
        "    a = torch.empty(N, N)\n",
        "    #nn.init.xavier_uniform_(a, gain=nn.init.calculate_gain('tanh'))\n",
        "    nn.init.xavier_uniform_(a, gain=1.0)\n",
        "    x = a @ x\n",
        "    mean_before_tanh.append(x.mean().item())\n",
        "    std_before_tanh.append(x.std().item())\n",
        "    x = torch.tanh(x)\n",
        "    mean.append(x.mean().item())\n",
        "    std.append(x.std().item())\n",
        "    # added code for visualizing the blow up effect\n",
        "    if i == 26:\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "    if torch.isnan(x.mean()) or torch.isnan(x.std()):\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "print(x.mean(), x.std())\n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize=(14, 16))\n",
        "\n",
        "ax[0, 0].set_title('The mean and std of $x$ before $tanh$ operation \\nusing nn.init.xavier_uniform_(a, gain=1.0)')\n",
        "ax[0, 0].plot(range(m), mean_before_tanh, label='x.mean', color='green')\n",
        "ax[0, 0].plot(range(m), std_before_tanh, label='x.std', color='purple')\n",
        "ax[0, 0].set_ylabel('Value')\n",
        "ax[0, 0].legend(loc='center right')\n",
        "ax[0, 0].set_xlabel('Iteration')\n",
        "ax[0, 0].grid()\n",
        "\n",
        "ax[0, 1].set_title('The mean and std of $x$ after $tanh$ operation \\nusing nn.init.xavier_uniform_(a, gain=1.0)')\n",
        "ax[0, 1].plot(range(m), mean, label='tanh(x).mean')\n",
        "ax[0, 1].plot(range(m), std, label='tanh(x).std')\n",
        "ax[0, 1].set_xlabel('Iteration')\n",
        "ax[0, 1].set_ylabel('Value')\n",
        "ax[0, 1].legend(loc='center left')\n",
        "ax[0, 1].grid()\n",
        "\n",
        "x = torch.randn(N)\n",
        "std = []\n",
        "mean = []\n",
        "std_before_tanh = []\n",
        "mean_before_tanh = []\n",
        "\n",
        "for i in range(m):\n",
        "    a = torch.empty(N, N)\n",
        "    nn.init.xavier_uniform_(a, gain=nn.init.calculate_gain('tanh'))\n",
        "    #nn.init.xavier_uniform_(a, gain=1.0)\n",
        "    x = a @ x\n",
        "    mean_before_tanh.append(x.mean().item())\n",
        "    std_before_tanh.append(x.std().item())\n",
        "    x = torch.tanh(x)\n",
        "    mean.append(x.mean().item())\n",
        "    std.append(x.std().item())\n",
        "    # added code for visualizing the blow up effect\n",
        "    if i == 26:\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "    if torch.isnan(x.mean()) or torch.isnan(x.std()):\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "print(x.mean(), x.std())\n",
        "\n",
        "ax[1, 0].set_title('The mean and std of $x$ before $tanh$ operation \\nusing nn.init.xavier_uniform_(a, gain=nn.init.calculate_gain(tanh))')\n",
        "ax[1, 0].plot(range(m), mean_before_tanh, label='x.mean', color='green')\n",
        "ax[1, 0].plot(range(m), std_before_tanh, label='x.std', color='purple')\n",
        "ax[1, 0].set_ylabel('Value')\n",
        "ax[1, 0].legend(loc='center right')\n",
        "ax[1, 0].set_xlabel('Iteration')\n",
        "ax[1, 0].grid()\n",
        "\n",
        "ax[1, 1].set_title('The mean and std of $x$ after $tanh$ operation \\nusing nn.init.xavier_uniform_(a, gain=nn.init.calculate_gain(tanh))')\n",
        "ax[1, 1].plot(range(m), mean, label='tanh(x).mean')\n",
        "ax[1, 1].plot(range(m), std, label='tanh(x).std')\n",
        "ax[1, 1].set_xlabel('Iteration')\n",
        "ax[1, 1].set_ylabel('Value')\n",
        "ax[1, 1].legend(loc='center left')\n",
        "ax[1, 1].grid()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvqA0mQQJmUy"
      },
      "source": [
        "5. We see that if we use the Xavier_init method to initialize the weights values we get different behavior which depends on the \"gain\". Using $tanh(x)$ activation in between layers we see that we need to choos a gain which corresponds to the $tanh(x)$ activation ($1.66666666$ in that case) in order to preserve the mean and std of $x$ along the feedforward process (lower plots). Using gain of $1.0$ we see that the forward-pass values vanish (upper plots)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOTBw3NWLNqE"
      },
      "source": [
        "N = 512\n",
        "m = 100\n",
        "x = torch.randn(N)\n",
        "std = []\n",
        "mean = []\n",
        "std_before_relu = []\n",
        "mean_before_relu = []\n",
        "\n",
        "for i in range(m):\n",
        "    a = torch.empty(N, N)\n",
        "    #nn.init.xavier_uniform_(a, gain=nn.init.calculate_gain('relu'))\n",
        "    nn.init.kaiming_normal_(a, mode='fan_in', nonlinearity='relu')\n",
        "    x = a @ x\n",
        "    mean_before_relu.append(x.mean().item())\n",
        "    std_before_relu.append(x.std().item())\n",
        "    torch.nn.ReLU(x)\n",
        "    mean.append(x.mean().item())\n",
        "    std.append(x.std().item())\n",
        "    # added code for visualizing the blow up effect\n",
        "    if i == 26:\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "    if torch.isnan(x.mean()) or torch.isnan(x.std()):\n",
        "      print('At layer num {}, mean(x) = {}, std(x) = {}'.format(i, x.mean(), x.std()))\n",
        "print(x.mean(), x.std())\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(22, 6))\n",
        "\n",
        "ax[0].set_title('The mean and std of $x$ before $tanh$ operation \\nusing nn.init.kaiming_normal_(a, mode=fan_in, nonlinearity=relu)')\n",
        "ax[0].plot(range(m), mean_before_relu, label='x.mean', color='green')\n",
        "ax[0].plot(range(m), std_before_relu, label='x.std', color='purple')\n",
        "ax[0].set_ylabel('Value')\n",
        "ax[0].legend(loc='center right')\n",
        "ax[0].set_xlabel('Iteration')\n",
        "ax[0].grid()\n",
        "\n",
        "ax[1].set_title('The mean and std of $x$ after $tanh$ operation \\nusing nn.init.kaiming_normal_(a, mode=fan_in, nonlinearity=relu)')\n",
        "ax[1].plot(range(m), mean, label='ReLU(x).mean')\n",
        "ax[1].plot(range(m), std, label='ReLU(x).std')\n",
        "ax[1].set_xlabel('Iteration')\n",
        "ax[1].set_ylabel('Value')\n",
        "ax[1].legend(loc='center left')\n",
        "ax[1].grid()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4tqTYXYRop2"
      },
      "source": [
        "6. It seems like when using the ReLU activation the weights blow up when initializing using Xavier_uniform which is expected but also when using Kaiming_normal. Maybe there is a problem with my implemintation, I need to check it again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sfe5TvUJ4Pm"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 2 - FashionMNIST Deep Classifer\n",
        "---\n",
        "In this task you are goin to design and train your first neural network for classification.\n",
        "1. Load the FashionMNIST dataset `torchvision.datasets.FashionMNIST` and display 6 images with their labels from the dataset.\n",
        "2. Design a **MLP** to classify images from the FashionMNIST dataset. **You need to reach at least 85% accuracy on the test set, and 89% for a full grade**.\n",
        "    * You have a free choice of architecture, optimizer, learning scheduler, initialization, regularization and activations.\n",
        "    * In a Markdown block, write down the chosen architectures and all the hyper-parameters.\n",
        "    * **Plot** the loss curves (and any oter statistic you want) as a function of epochs/iterations.\n",
        "    * **Print** the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me7zrAI1Kvus"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    \"\"\"Add Gaussian noise to Pytorch's tensor\"\"\"\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'mean={self.mean}, std={self.std}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCyVNTGZQUgV"
      },
      "source": [
        "MNIST_CHECKPOINT_DIR = 'checkpoints_MNIST'\n",
        "MNIST_DATASET_DIR = 'datasets_MNIST'\n",
        "MODEL_NAME = 'FashionMNIST_MLP'\n",
        "\n",
        "\n",
        "\n",
        "# create checkpoint directory to save model results\n",
        "if not os.path.isdir(MNIST_CHECKPOINT_DIR):\n",
        "    os.mkdir(MNIST_CHECKPOINT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGydMOYSME7j"
      },
      "source": [
        "def get_data_transform():\n",
        "    \"\"\"Define the data augmentation to apply on the train, validation and test\"\"\"\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        #transforms.RandomAffine(degrees=10),\n",
        "        #transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914,), (0.2023,),),\n",
        "        AddGaussianNoise(0., 0.4),\n",
        "    ])\n",
        "\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914,), (0.2023,),),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914,), (0.2023,),),\n",
        "    ])\n",
        "\n",
        "    return train_transform, valid_transform, test_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10j3sjgtMi36"
      },
      "source": [
        "def get_dataset(train_transform, valid_transform, test_transform, data_dir):\n",
        "    \"\"\"Get the datasets for train, validation and test\"\"\"\n",
        "    train_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root=data_dir, train=True, transform=train_transform, download=True\n",
        "    )\n",
        "    valid_dataset = torchvision.datasets.FashionMNIST(\n",
        "        root=data_dir, train=True, transform=valid_transform, download=True\n",
        "    )\n",
        "    test_dataset  = torchvision.datasets.FashionMNIST(\n",
        "        root=data_dir, train=False, transform=test_transform, download = True\n",
        "    )\n",
        "\n",
        "    return train_dataset, valid_dataset, test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgbkYkrvMi_g"
      },
      "source": [
        "def get_data_loader(batch_size, valid_size=0.2, data_dir=MNIST_DATASET_DIR):\n",
        "    \"\"\"Get the train, validation and test data loaders\"\"\"\n",
        "\n",
        "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
        "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
        "\n",
        "    # get transform\n",
        "    train_transform, valid_transform, test_transform = get_data_transform()\n",
        "\n",
        "    # load dataset\n",
        "    train_dataset, valid_dataset, test_dataset = get_dataset(\n",
        "        train_transform, valid_transform, test_transform, data_dir\n",
        "    )\n",
        "    \n",
        "    # split the data\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # shuffle\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    loader_settings = {\n",
        "        'batch_size': batch_size,\n",
        "        'num_workers': 1,\n",
        "        'pin_memory': torch.cuda.is_available()\n",
        "    }\n",
        "\n",
        "    # get dataloader objects\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, **loader_settings\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset, sampler=valid_sampler, **loader_settings\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, shuffle=False, **loader_settings\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DwBVE-KOJ4Pn"
      },
      "source": [
        "def output_label(label):\n",
        "    output_mapping = {\n",
        "                 0: \"T-shirt/Top\",\n",
        "                 1: \"Trouser\",\n",
        "                 2: \"Pullover\",\n",
        "                 3: \"Dress\",\n",
        "                 4: \"Coat\",\n",
        "                 5: \"Sandal\",\n",
        "                 6: \"Shirt\",\n",
        "                 7: \"Sneaker\",\n",
        "                 8: \"Bag\",\n",
        "                 9: \"Ankle Boot\"\n",
        "                 }\n",
        "    input = (label.item() if type(label) == torch.Tensor else label)\n",
        "    return output_mapping[input]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Kyv5O5SEJ4Pn"
      },
      "source": [
        "1. First let us display the first 6 images in the training data set with their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTH8_sxJVB_S"
      },
      "source": [
        "# load n images\n",
        "train_transform, _, _ = get_data_transform()\n",
        "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, \n",
        "                                              transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=6, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bYIp102J4Pn"
      },
      "source": [
        "# let's see some of the images\n",
        "def convert_to_imshow_format(image):\n",
        "    # first convert back to [0,1] range from [-1,1] range - approximately...\n",
        "    image = image / 2 + 0.5\n",
        "    image = image.numpy()\n",
        "    return np.squeeze(image)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# plot images with labels\n",
        "fig, axes = plt.subplots(1, len(images), figsize=(12,2.5))\n",
        "for idx, image in enumerate(images):\n",
        "    axes[idx].imshow(convert_to_imshow_format(image))\n",
        "    axes[idx].set_title(output_label(labels[idx]))\n",
        "    axes[idx].set_xticks([])\n",
        "    axes[idx].set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CxAqMiCAJ4Po"
      },
      "source": [
        "2. Next let us train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nfeqP-9TJ4Po"
      },
      "source": [
        "# define the nn model\n",
        "class FashionMnistMLP(nn.Module):\n",
        "    \"MLP for Fashion MNIST\"\n",
        "    def __init__(self, ):\n",
        "        super(FashionMnistMLP, self).__init__()\n",
        "        # define the layers of the MLP\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            \n",
        "            # fc_1\n",
        "            nn.Linear(784, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.05),\n",
        "            \n",
        "            # fc_2\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.05),\n",
        "            \n",
        "            # fc_3\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.05),\n",
        "            \n",
        "            # fc_4\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            \n",
        "            # fc_5\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            \n",
        "            # output\n",
        "            nn.Linear(32, 10),\n",
        "        )\n",
        "            \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"forward pass\"\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layers\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d-w1lcCKJ4Po"
      },
      "source": [
        "# define hyper-parmeters\n",
        "batch_size = 32\n",
        "learning_rate = 0.00005\n",
        "num_epochs = 100\n",
        "whight_decay = learning_rate/110\n",
        "\n",
        "# Load the dataset\n",
        "train_loader, valid_loader, test_loader = get_data_loader(batch_size, \n",
        "                                                          valid_size=0.2, \n",
        "                                                          )\n",
        "# device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# model\n",
        "model = FashionMnistMLP().to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), \n",
        "                             lr=learning_rate, \n",
        "                             amsgrad=True, \n",
        "                             weight_decay=whight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRZsBzhdVdvM"
      },
      "source": [
        "print(model)\n",
        "\n",
        "# how many weights (trainable parameters) we have in our model?\n",
        "dummy_model = FashionMnistMLP()\n",
        "num_trainable_params = sum([p.numel() for p in dummy_model.parameters() if p.requires_grad])\n",
        "print(\"num trainable weights: \", num_trainable_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R5hdBuBWXw4"
      },
      "source": [
        "# visualize computational graph\n",
        "x = torch.randn(1, 784).to(device) \n",
        "torchviz.make_dot(model(x), params=dict(model.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjAEo0thJ4Pp"
      },
      "source": [
        "# function to calcualte accuracy of the model - taken from the toturial\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval() # put in evaluation mode\n",
        "    total_correct = 0\n",
        "    total_images = 0\n",
        "    confusion_matrix = np.zeros([10,10], int)\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_images += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            for i, l in enumerate(labels):\n",
        "                confusion_matrix[l.item(), predicted[i].item()] += 1\n",
        "                \n",
        "    model_accuracy = total_correct / total_images * 100\n",
        "    return model_accuracy, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qghOY8BYJ4Pp"
      },
      "source": [
        "# dict for saving logs \n",
        "logger = {\n",
        "    'loss': [],\n",
        "    'train_acc': [],\n",
        "    'valid_acc': [],\n",
        "    'epochs': [],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzY5DaBsJ4Pp"
      },
      "source": [
        "# training loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train() # put in training mode\n",
        "    running_loss = 0.0\n",
        "    epoch_time = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # send them to device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)           # forward pass\n",
        "        loss = criterion(outputs, labels) # calculate the loss\n",
        "        optimizer.zero_grad()             # zero the parameter gradients\n",
        "        loss.backward()                   # backpropagation\n",
        "        optimizer.step()                  # update parameters\n",
        "        \n",
        "        # calculate loss\n",
        "        running_loss += loss.data.item()\n",
        "        running_loss /= len(trainloader)\n",
        "        \n",
        "    # Calculate training + valid sets accuracy\n",
        "    train_accuracy, _ = calculate_accuracy(model, train_loader, device)\n",
        "    valid_accuracy, _ = calculate_accuracy(model, valid_loader, device)\n",
        "    log = \"Epoch: {} | Loss: {:.6f} | Training accuracy: {:.3f}% | valid accuracy: {:.3f}% | \".format(epoch\n",
        "    , running_loss, train_accuracy, valid_accuracy)\n",
        "    epoch_time = time.time() - epoch_time\n",
        "    log += \"Epoch Time: {:.2f} secs\".format(epoch_time)\n",
        "    print(log)\n",
        "    \n",
        "    # save log into logger\n",
        "    logger['loss'].append(running_loss)\n",
        "    logger['train_acc'].append(train_accuracy)\n",
        "    logger['valid_acc'].append(valid_accuracy)\n",
        "    logger['epochs'].append(epoch)\n",
        "\n",
        "    # save the model\n",
        "    state = {\n",
        "        'net': model.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss': loss,\n",
        "        'train_acc': train_accuracy,\n",
        "        'valid_acc': valid_accuracy,\n",
        "    }\n",
        "    torch.save(state, f'{MNIST_CHECKPOINT_DIR}/{MODEL_NAME}_{epoch}.pth')\n",
        "print('==> Finished Training ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saH-aG26J4Pq"
      },
      "source": [
        "# load saved model\n",
        "model = FashionMnistMLP().to(device)\n",
        "state = torch.load(f'{MNIST_CHECKPOINT_DIR}/{MODEL_NAME}_{num_epochs - 1}.pth', map_location=device)\n",
        "model.load_state_dict(state['net'])\n",
        "\n",
        "# calculte test accuracy\n",
        "test_accuracy, confusion_matrix = calculate_accuracy(model, test_loader, device)\n",
        "print('Test accuracy: {}'.format(test_accuracy))\n",
        "\n",
        "CLASSES = {\n",
        "    0: 'T-shirt/Top', \n",
        "    1: 'Trouser', \n",
        "    2: 'Pullover', \n",
        "    3: 'Dress', \n",
        "    4: 'Coat', \n",
        "    5: 'Sandal', \n",
        "    6: 'Shirt', \n",
        "    7: 'Sneaker', \n",
        "    8: 'Bag', \n",
        "    9: 'Ankle Boot'\n",
        "}\n",
        "\n",
        "\n",
        "# plot confusion matrix\n",
        "fig, ax = plt.subplots(1,1,figsize=(8, 8))\n",
        "ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n",
        "plt.ylabel('Actual Category')\n",
        "plt.yticks(range(10), CLASSES.values())\n",
        "plt.xlabel('Predicted Category')\n",
        "plt.xticks(range(10), CLASSES.values())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNP09BFZd0Sk"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15,8), dpi=200)\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# plot accuracy\n",
        "p1 = ax.plot(logger['epochs'], logger['train_acc'], linewidth=2, label='train\\naccuracy')\n",
        "p2 = ax.plot(logger['epochs'], logger['valid_acc'], linewidth=2, label='validation\\naccuracy')\n",
        "ax.set_xticks(range(0, num_epochs + 1, 10))\n",
        "ax.set_xticklabels(range(0, num_epochs + 1, 10))\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy [%]')\n",
        "ax.set_title('Model Accuracy and Loss')\n",
        "ax.xaxis.grid()\n",
        "ax1 = ax.twinx()\n",
        "ax1.set_ylabel('Loss')\n",
        "p3 = ax1.plot(logger['epochs'], logger['loss'], linewidth=2, label='loss')\n",
        "\n",
        "# Add legend\n",
        "lns = p1 + p2 + p3\n",
        "labs = [l.get_label() for l in lns]\n",
        "ax.legend(lns, labs, loc='upper center', ncol=3, frameon=False, bbox_to_anchor=(0.35, 1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfSd3mSJ4Pr"
      },
      "source": [
        "2. So I trained a MLP network with the next architecture,\n",
        "\n",
        "\n",
        "**Architecture:**\n",
        "\n",
        "- Fully-conected ($784\\to512$)\n",
        "- ReLU\n",
        "- Dropout ($5$%)\n",
        "- Fully-conected ($512\\to256$)\n",
        "- ReLU\n",
        "- Dropout ($5$%)\n",
        "- Fully-conected ($256\\to128$)\n",
        "- ReLU\n",
        "- Dropout ($5$%)\n",
        "- Fully-conected ($128\\to64$)\n",
        "- ReLU\n",
        "- Dropout ($10$%)\n",
        "- Fully-conected ($64\\to32$)\n",
        "- ReLU\n",
        "- Dropout ($10$%)\n",
        "- Fully-conected ($32\\to10$)\n",
        "\n",
        "where first I flatten the $28\\times 28$ image into a $784$ long vector. The output of the network is of size $10$ because the fashionMNIST dataset has $10$ classes overall. The number of layers and their sizes was chosen with a trail and error method until I got enough good results on the validation set.\n",
        "\n",
        "**Hyper-parmeters:**\n",
        "\n",
        "- batch size = $32$\n",
        "- learning rate = $0.00005$\n",
        "- num epochs = $100$\n",
        "- whight decay = learning_rate$/110$\n",
        "- dropouts (shown in the architecture above)\n",
        "\n",
        "There wasn't a lot of hyper-parameters optimization because this is an easy dataset. But, the little optimization I had was with respect to the validation set which was independent from the train and test datasets.\n",
        "\n",
        "\n",
        "**Data augmentation:**\n",
        "\n",
        "I used few types of transforms for data augmentation:\n",
        "\n",
        "- Random horizontal flip\n",
        "- Adding gaussian noise to images\n",
        "\n",
        "At first I also used crop with padding which didn't give to good of results over the validation set. This wasn't surprising given th fact that the test aand validations set have all of the images centered and not cropped, so using a crop and pad augmentation would force the model to generalize on a data which is not found in the test set, what obviously caused a degradation in performance.\n",
        "\n",
        "Finally, I got an accurcy larger then $89$% as asked so I stoped there. But, it definitely seems like we could get even better accuracy by taking the hyper-parameters optimization more seriously. Because this is a long homework assignement I didn't take the time to fully optimize the model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buplflpeJ4Pr"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 3 - Design a CNN\n",
        "---\n",
        "In this task you are going to design a deep convolutional neural network to classify house number digits from the **The Street View House Numbers (SVHN)** Dataset. \n",
        "\n",
        "SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n",
        "\n",
        "* 10 classes, 1 for each digit. Digit '0' has label 0, '1' has label 1,...\n",
        "* 73257 digits for training, 26032 digits for testing, and 531131 additional, somewhat less difficult samples, to use as extra training data.\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/housenumbers/32x32eg.png\" style=\"height:250px\">\n",
        "\n",
        "1. Load the SVHN dataset with PyTorch using `torchvision.datasets.SVHN(root, split='train', transform=None, target_transform=None, download=True)`, you can read more here: https://pytorch.org/docs/stable/torchvision/datasets.html#svhn. Display 5 images from the train set.\n",
        "2. Design a Convolutional Neural Network (CNN) to classify digits from the images.\n",
        "    * Describe the chosen architecture, how many layers? What activations did you choose? What are the filter sizes? Did you use fully-connected layers (if you did, explain their sizes)?\n",
        "    * What is the input dimension? What is the output dimension?\n",
        "    * Calculate the number of parameters (weights) in the network. **Print** this number.\n",
        "    * **Important** - if you used the CNN from the tutorial (`CifarCNN()`), **explain what you changed!**\n",
        "3. Train the classifier (preferably on a GPU - use Colab for this part if you don't have a GPU).\n",
        "    * Describe the the hyper-parameters of the model (batch size, epochs, learning rate....). How did you tune your model? Did you use a validation set to tune the model?\n",
        "    * What is the final accuracy on the test set? **Print** it.\n",
        "        * You need to reach at least 86% accuracy in this section, and 90% for a full grade.\n",
        "    * **Plot** the loss curves (and any other statistic you want) as a function of epochs/iterations.\n",
        "4. For the trained classifier, what is the accuracy on the test set when each test image is added a small noise $$ \\text{image} + 0.005 \\times \\mathcal{N}(0, 1) $$. **Print** the result.\n",
        "5. Retrain the classifier, but this time use data augementation of your choosing. Briefly explain what augmentation you chose and how it works. Did the test accuracy improve? **Print** the result.\n",
        "    * You can use transformations available in `torchvision.transforms` as shown in the tutorial.\n",
        "    * **Plot** the loss curves (and any other statistic you want) as a function of epochs/iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJg1qMPxQUpd"
      },
      "source": [
        "!pip install torchviz\n",
        "\n",
        "# imports for the practice (you can add more if you need)\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib notebook\n",
        "%matplotlib inline\n",
        "\n",
        "seed = 211\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5BVxiwY2zX1"
      },
      "source": [
        "SVHN_CHECKPOINT_DIR = 'checkpoints_SVHN'\n",
        "SVHN_DATASET_DIR = 'datasets_SVHN'\n",
        "MODEL_NAME = 'SVHN_CNN'\n",
        "CLASSES = {\n",
        "    0: '0', \n",
        "    1: '1', \n",
        "    2: '2', \n",
        "    3: '3', \n",
        "    4: '4', \n",
        "    5: '5', \n",
        "    6: '6', \n",
        "    7: '7', \n",
        "    8: '8', \n",
        "    9: '9'\n",
        "}\n",
        "\n",
        "# create checkpoint directory to save model results\n",
        "if not os.path.isdir(SVHN_CHECKPOINT_DIR):\n",
        "    os.mkdir(SVHN_CHECKPOINT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47EUNsTv4zhG"
      },
      "source": [
        "################################################################################\n",
        "#        USEFUL DATA TRANSFORMS, DOWNLOAD and DATALOADER FUNCTIONS             #     \n",
        "################################################################################\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    \"\"\"Add Gaussian noise to Pytorch's tensor\"\"\"\n",
        "    def __init__(self, mean=0., std=1., p=0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "      if torch.rand(1).item() <= self.p:\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "      else:\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'mean={self.mean}, std={self.std}'\n",
        "\n",
        "\n",
        "def get_data_transform():\n",
        "    \"\"\"Define the data augmentation to apply on the train, validation and test\"\"\"\n",
        "    normalize_image = transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                           (0.2023, 0.1994, 0.2010))\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomAffine(degrees=10),\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        #transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        normalize_image,\n",
        "        AddGaussianNoise(0., 0.2, p=0.5),\n",
        "    ])\n",
        "\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize_image,\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize_image,\n",
        "    ])\n",
        "\n",
        "    return train_transform, valid_transform, test_transform\n",
        "\n",
        "\n",
        "def get_dataset(train_transform, valid_transform, test_transform, data_dir):\n",
        "    \"\"\"Get the datasets for train, validation and test\"\"\"\n",
        "    train_dataset = torchvision.datasets.SVHN(\n",
        "        root=data_dir, split='train', transform=train_transform, download=True\n",
        "    )\n",
        "    valid_dataset = torchvision.datasets.SVHN(\n",
        "        root=data_dir, split='train', transform=valid_transform, download=True\n",
        "    )\n",
        "    test_dataset  = torchvision.datasets.SVHN(\n",
        "        root=data_dir, split='test', transform=test_transform, download=True\n",
        "    )\n",
        "\n",
        "    return train_dataset, valid_dataset, test_dataset    \n",
        "\n",
        "\n",
        "def get_data_loader(batch_size, valid_size=0.2, data_dir=SVHN_DATASET_DIR):\n",
        "    \"\"\"Get the train, validation and test data loaders\"\"\"\n",
        "\n",
        "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
        "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
        "\n",
        "    # get transform\n",
        "    train_transform, valid_transform, test_transform = get_data_transform()\n",
        "\n",
        "    # load dataset\n",
        "    train_dataset, valid_dataset, test_dataset = get_dataset(\n",
        "        train_transform, valid_transform, test_transform, data_dir\n",
        "    )\n",
        "    \n",
        "    # split the data\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # shuffle\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    loader_settings = {\n",
        "        'batch_size': batch_size,\n",
        "        'num_workers': 1,\n",
        "        'pin_memory': torch.cuda.is_available()\n",
        "    }\n",
        "\n",
        "    # get dataloader objects\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, **loader_settings\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset, sampler=valid_sampler, **loader_settings\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, shuffle=False, **loader_settings\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_jVvXfJJ4Pr"
      },
      "source": [
        "# loading some data\n",
        "train_transform, _, _ = get_data_transform()\n",
        "train_set = torchvision.datasets.SVHN(SVHN_DATASET_DIR, \n",
        "                                      split='train', \n",
        "                                      transform=train_transform, \n",
        "                                      target_transform=None, \n",
        "                                      download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ga75Q4OEAAI"
      },
      "source": [
        "1. Next let us plot some images from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWv2z6zH3p1B"
      },
      "source": [
        "# let's see some of the images\n",
        "def convert_to_imshow_format(image):\n",
        "    # first convert back to [0,1] range from [-1,1] range - approximately...\n",
        "    image = image / 2 + 0.5\n",
        "    image = image.numpy()\n",
        "    \n",
        "    # for single channel images \n",
        "    if image.shape[0] == 1:\n",
        "      return np.squeeze(image)\n",
        "    \n",
        "    # for images with more than 1 channel\n",
        "    elif image.shape[0] > 1:\n",
        "      return image.transpose(1, 2, 0)\n",
        "\n",
        "def grid_plot(images, labels, ncols=5):\n",
        "  # plot a grid of images of shape (len(images) / ncols, ncols)\n",
        "  nrows = np.int(np.ceil(len(labels) / ncols))\n",
        "\n",
        "  # plot images with labels\n",
        "  fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(2 * ncols, 2 * nrows))\n",
        "  for idx, image in enumerate(images):\n",
        "    if len(axes.shape) == 1:\n",
        "      axes[idx].imshow(convert_to_imshow_format(image))\n",
        "      axes[idx].set_title(CLASSES[labels[idx].item()])\n",
        "      axes[idx].set_xticks([])\n",
        "      axes[idx].set_yticks([])\n",
        "    else:  \n",
        "      i, j = np.unravel_index(idx, (nrows, ncols))\n",
        "      axes[i, j].imshow(convert_to_imshow_format(image))\n",
        "      axes[i, j].set_title(CLASSES[labels[idx].item()])\n",
        "      axes[i, j].set_xticks([])\n",
        "      axes[i, j].set_yticks([])\n",
        "\n",
        "trainloader = DataLoader(train_set, batch_size=20, shuffle=False)\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "grid_plot(images, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh75V-sM9xUr"
      },
      "source": [
        "class SVHN_CNN(nn.Module):\n",
        "    \"\"\"CNN for the SVHN Datset\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(SVHN_CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njS7USUbHqeN"
      },
      "source": [
        "print(SVHN_CNN())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeIMXtWlGqPY"
      },
      "source": [
        "2. As a first step I used the CFAR-10 network from the tutorial without a change. The results I got was on the first try, so I didn't had any change to tweak the hyper-parameters and change the network.\n",
        "\n",
        "##**Network Architecture:**\n",
        "\n",
        "**Convolution layer block 1**\n",
        "- 2D Convolution - channels: $3\\to32$, kernel: ($3, 3$), stride: ($1, 1$), pad: ($1, 1$)\n",
        "- 2D Batch norm - features: $32$\n",
        "- ReLU\n",
        "- 2D Convolution - channels: $32\\to64$, kernel: ($3, 3$), stride: ($1, 1$), pad: ($1, 1$)\n",
        "- ReLU\n",
        "- Max pooling - kernel: $2$, stride: $2$, pad: $0$\n",
        "\n",
        "**Convolution layer block 2**\n",
        "- 2D Convolution - channels: $64\\to128$, kernel: ($3, 3$), stride: ($1, 1$), pad: ($1, 1$)\n",
        "- 2D Batch norm - features: $128$\n",
        "- ReLU\n",
        "- 2D Convolution - channels: $128\\to128$, kernel: ($3, 3$), stride: ($1, 1$), pad: ($1, 1$)\n",
        "- ReLU\n",
        "- Max pooling - kernel: $2$, stride: $2$, pad: $0$\n",
        "- Dropout - $5$%\n",
        "\n",
        "**Convolution layer block 3**\n",
        "- 2D Convolution - channels: $128\\to256$, kernel: ($3, 3$), stride: ($1, 1$), pad: ($1, 1$)\n",
        "- 2D Batch norm - features: $256$\n",
        "- ReLU\n",
        "- 2D Convolution - channels: $256\\to256$, kernel: ($3, 3$), stride: ($1, 1$), pad: ($1, 1$)\n",
        "- ReLU\n",
        "- Max pooling - kernel: $2$, stride: $2$, pad: $0$\n",
        "\n",
        "\n",
        "**Fully conected layer block**\n",
        "- Dropout - $10$%\n",
        "- Fully conected - $4096\\to1024$\n",
        "- ReLU\n",
        "- Fully conected - $1024\\to512$\n",
        "- ReLU\n",
        "- Dropout - $10$%\n",
        "- Fully conected - $512\\to10$\n",
        "\n",
        "\n",
        "## **Hyper parameters**\n",
        "I started with exactly the same parameters as in the FashionMNIST network before and got great results so I didn't tune them at all.\n",
        "\n",
        "- batch size = $32$\n",
        "- learning rate = $0.00005$\n",
        "- num epochs = $100$\n",
        "- wheight decay = learning_rate$/110$\n",
        "\n",
        "\n",
        "## **Data Augmentation**\n",
        "In this dataset I also used data augmentation, but this time, because number comes in a specific orientation, I didn't use random flip. Instead, I used \n",
        "\n",
        "- Random Affine transform\n",
        "- Color Jitter transform\n",
        "- Adding Gaussian noise (with probability of p=$0.5$ for each image)\n",
        "- Normalization with the same parameters from the tutorial\n",
        "\n",
        "## **Dimensions**\n",
        "The input dimension was images with $3$ channels of size $32\\times32$ pixels so $(3, 32, 32)$\n",
        "\n",
        "The output dimention was $10$, which is the number of classes in the dataset labels $(0,1,...,9)$.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGhwmRuSHJQa"
      },
      "source": [
        "# define hyper-parmeters\n",
        "batch_size = 32\n",
        "learning_rate = 0.00005\n",
        "num_epochs = 10\n",
        "whight_decay = learning_rate/110\n",
        "\n",
        "# Load the dataset\n",
        "train_loader, valid_loader, test_loader = get_data_loader(batch_size, \n",
        "                                                          valid_size=0.2, \n",
        "                                                          )\n",
        "# device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# model\n",
        "model = SVHN_CNN().to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), \n",
        "                             lr=learning_rate, \n",
        "                             amsgrad=True, \n",
        "                             weight_decay=whight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bnhUVKHH8Ch"
      },
      "source": [
        "# function to calcualte accuracy of the model - taken from the toturial\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval() # put in evaluation mode\n",
        "    total_correct = 0\n",
        "    total_images = 0\n",
        "    confusion_matrix = np.zeros([10, 10], int)\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_images += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            for i, l in enumerate(labels):\n",
        "                confusion_matrix[l.item(), predicted[i].item()] += 1\n",
        "                \n",
        "    model_accuracy = total_correct / total_images * 100\n",
        "    return model_accuracy, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-VFdP2oIJD7"
      },
      "source": [
        "# dict for saving logs \n",
        "logger = {\n",
        "    'loss': [],\n",
        "    'train_acc': [],\n",
        "    'valid_acc': [],\n",
        "    'epochs': [],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuLhYFieIJL-"
      },
      "source": [
        "# training loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train() # put in training mode\n",
        "    running_loss = 0.0\n",
        "    epoch_time = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # send them to device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)           # forward pass\n",
        "        loss = criterion(outputs, labels) # calculate the loss\n",
        "        optimizer.zero_grad()             # zero the parameter gradients\n",
        "        loss.backward()                   # backpropagation\n",
        "        optimizer.step()                  # update parameters\n",
        "        \n",
        "        # calculate loss\n",
        "        running_loss += loss.data.item()\n",
        "        running_loss /= len(trainloader)\n",
        "        \n",
        "    # Calculate training + valid sets accuracy\n",
        "    train_accuracy, _ = calculate_accuracy(model, train_loader, device)\n",
        "    valid_accuracy, _ = calculate_accuracy(model, valid_loader, device)\n",
        "    log = \"Epoch: {} | Loss: {:.6f} | Training accuracy: {:.3f}% | valid accuracy: {:.3f}% | \".format(epoch\n",
        "    , running_loss, train_accuracy, valid_accuracy)\n",
        "    epoch_time = time.time() - epoch_time\n",
        "    log += \"Epoch Time: {:.2f} secs\".format(epoch_time)\n",
        "    print(log)\n",
        "    \n",
        "    # save log into logger\n",
        "    logger['loss'].append(running_loss)\n",
        "    logger['train_acc'].append(train_accuracy)\n",
        "    logger['valid_acc'].append(valid_accuracy)\n",
        "    logger['epochs'].append(epoch)\n",
        "\n",
        "    # save the model\n",
        "    state = {\n",
        "        'net':        model.state_dict(),\n",
        "        'epoch':      epoch,\n",
        "        'loss':       loss,\n",
        "        'train_acc':  train_accuracy,\n",
        "        'valid_acc':  valid_accuracy,\n",
        "        'logger':     logger,\n",
        "    }\n",
        "    torch.save(state, f'{SVHN_CHECKPOINT_DIR}/{MODEL_NAME}_{epoch}.pth')\n",
        "print('==> Finished Training ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5C1dGvLIJVz"
      },
      "source": [
        "# load saved model\n",
        "model = SVHN_CNN().to(device)\n",
        "state = torch.load(f'{SVHN_CHECKPOINT_DIR}/{MODEL_NAME}_{num_epochs - 1}.pth', map_location=device)\n",
        "model.load_state_dict(state['net'])\n",
        "\n",
        "# calculte test accuracy\n",
        "test_accuracy, confusion_matrix = calculate_accuracy(model, test_loader, device)\n",
        "print()\n",
        "print('Test accuracy: {}'.format(test_accuracy))\n",
        "\n",
        "\n",
        "# plot confusion matrix\n",
        "fig, ax = plt.subplots(1,1,figsize=(8, 8))\n",
        "ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n",
        "plt.ylabel('Actual Category')\n",
        "plt.yticks(range(10), CLASSES.values())\n",
        "plt.xlabel('Predicted Category')\n",
        "plt.xticks(range(10), CLASSES.values())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8yJKOyhYfFY"
      },
      "source": [
        "def print_msg_box(msg, indent=1, width=None, title=None):\n",
        "    \"\"\"Print message-box with optional title.\"\"\"\n",
        "    lines = msg.split('\\n')\n",
        "    space = \" \" * indent\n",
        "    if not width:\n",
        "        width = max(map(len, lines))\n",
        "    box = f'{\"\" * (width + indent * 2)}\\n'  # upper_border\n",
        "    if title:\n",
        "        box += f'{space}{title:<{width}}{space}\\n'  # title\n",
        "        box += f'{space}{\"-\" * len(title):<{width}}{space}\\n'  # underscore\n",
        "    box += ''.join([f'{space}{line:<{width}}{space}\\n' for line in lines])\n",
        "    box += f'{\"\" * (width + indent * 2)}'  # lower_border\n",
        "    print(box)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlb2KPknYhN1"
      },
      "source": [
        "print_msg_box('Test accuracy: ' + str(np.round(test_accuracy, 2)) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6P1nJSzIJeW"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(12,6))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# plot accuracy\n",
        "p1 = ax.plot(logger['epochs'], logger['train_acc'], linewidth=2, label='train\\naccuracy')\n",
        "p2 = ax.plot(logger['epochs'], logger['valid_acc'], linewidth=2, label='validation\\naccuracy')\n",
        "ax.set_xticks(range(0, num_epochs + 1, 1))\n",
        "ax.set_xticklabels(range(0, num_epochs + 1, 1))\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy [%]')\n",
        "ax.set_title('Model Accuracy and Loss')\n",
        "ax.xaxis.grid()\n",
        "ax1 = ax.twinx()\n",
        "ax1.set_ylabel('Loss')\n",
        "p3 = ax1.plot(logger['epochs'], logger['loss'], linewidth=2, label='loss')\n",
        "\n",
        "# Add legend\n",
        "lns = p1 + p2 + p3\n",
        "labs = [l.get_label() for l in lns]\n",
        "ax.legend(lns, labs, loc='upper center', ncol=3, frameon=False, bbox_to_anchor=(0.35, 1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MExozajNPNhd"
      },
      "source": [
        "3. So I tarined a network, and as I mentioned in question 2 I didn't optimize the hyper-parameters because the results were good enogth on the first try. Nevertheless, at each training epoch I calculted the accuracy over a validetion set in case I would need to optimze some parameters. The loss and accuracy curves are plotted above and the final accuracy (over the test set) is turned out to be $93.9$%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZPCx1-kZjsa"
      },
      "source": [
        "4. Next let us calculate the accuracy of the model over the test set where each test image is added with a bit of gaussian noise as follows\n",
        "$$ \\text{image} + 0.005 \\times \\mathcal{N}(0, 1) $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrDOZ873axx8"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    \"\"\"Add Gaussian noise to Pytorch's tensor\"\"\"\n",
        "    def __init__(self, mean=0., std=1., a=0.005):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.a = a\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + self.a * torch.randn(tensor.size()) * self.std + self.mean\n",
        "      \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'mean={self.mean}, std={self.std}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjU7mEz9Z5lE"
      },
      "source": [
        "# load saved model\n",
        "model = SVHN_CNN().to(device)\n",
        "state = torch.load(f'{SVHN_CHECKPOINT_DIR}/{MODEL_NAME}_{num_epochs - 1}.pth', map_location=device)\n",
        "model.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "a_list = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1., 2., 5.]\n",
        "noisy_test_accuracy = []\n",
        "\n",
        "for a in a_list:\n",
        "  # preper the transform with noise\n",
        "  test_transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "      AddGaussianNoise(a=a),  # adding gaussian noise\n",
        "  ])\n",
        "\n",
        "  # get data set\n",
        "  test_dataset = torchvision.datasets.SVHN(SVHN_DATASET_DIR, \n",
        "                                        split='test', \n",
        "                                        transform=test_transform, \n",
        "                                        target_transform=None, \n",
        "                                        download=True)\n",
        "\n",
        "  # get data loader\n",
        "  loader_settings = {\n",
        "      'batch_size': 32,\n",
        "      'num_workers': 1,\n",
        "      'pin_memory': torch.cuda.is_available()\n",
        "  }\n",
        "  test_loader = DataLoader(test_dataset, shuffle=False, **loader_settings)\n",
        "\n",
        "  # calculte test accuracy\n",
        "  test_accuracy, _ = calculate_accuracy(model, test_loader, device)\n",
        "  noisy_test_accuracy.append(test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzz1Dv-NfyZ2"
      },
      "source": [
        "# plot noisy test accuracy for different noise values\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12,6))\n",
        "fig.patch.set_facecolor('white')\n",
        "p1 = ax.semilogx(a_list, noisy_test_accuracy, linewidth=2, label='noisy test accuracy')\n",
        "ax.set_xticks(a_list)\n",
        "ax.set_xticklabels(a_list)\n",
        "ax.set_xlabel('Noise factor')\n",
        "ax.set_ylabel('Accuracy [%]')\n",
        "ax.set_title('Model Accuracy over noisy test dataset: image + a * N(0, 1)')\n",
        "ax.scatter(a_list[2], noisy_test_accuracy[2], color='red', label='$a=0.005$')\n",
        "ax.text(a_list[2], noisy_test_accuracy[2] - 5, 'acc = ' + str(np.round(noisy_test_accuracy[2], 2)) + '%')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2umkULYyhet8"
      },
      "source": [
        "It seems like noise of $0.005 * \\mathcal{N}(0,1)$ has no difference on the accuracy. The reason for the good performence of the model could be because I trained the model on data with gaussian noise. In the training process I transform approximatlly half of the data to data with guassian noise with a factor $a=1$ which is almost three orders of magnitude larger than $a=0.005$. In the plot above we can see that for noise factor larger than $a=1$ the performence of the model drop rapidly which supports my explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2nMlf4IjuqD"
      },
      "source": [
        "5. I just saw that the main goal was to first train the model without augmentation and then check the accuracy over a noisy dataset while later train over noisy training set and compare the accuarcy in both cases. So now I will train the model again over clean dataset (without noise) and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhZYjEVckhWQ"
      },
      "source": [
        "################################################################################\n",
        "#        USEFUL DATA TRANSFORMS, DOWNLOAD and DATALOADER FUNCTIONS             #     \n",
        "################################################################################\n",
        "\n",
        "class AddGaussianNoise(object):\n",
        "    \"\"\"Add Gaussian noise to Pytorch's tensor\"\"\"\n",
        "    def __init__(self, mean=0., std=1., p=0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "      if torch.rand(1).item() <= self.p:\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "      else:\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'mean={self.mean}, std={self.std}'\n",
        "\n",
        "\n",
        "def get_data_transform():\n",
        "    \"\"\"Define the data augmentation to apply on the train, validation and test\"\"\"\n",
        "    normalize_image = transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
        "                                           (0.2023, 0.1994, 0.2010))\n",
        "    train_transform = transforms.Compose([\n",
        "        #transforms.RandomAffine(degrees=10),\n",
        "        #transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        #transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        normalize_image,\n",
        "        #AddGaussianNoise(0., 0.2, p=0.5),\n",
        "    ])\n",
        "\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize_image,\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize_image,\n",
        "    ])\n",
        "\n",
        "    return train_transform, valid_transform, test_transform\n",
        "\n",
        "\n",
        "def get_dataset(train_transform, valid_transform, test_transform, data_dir):\n",
        "    \"\"\"Get the datasets for train, validation and test\"\"\"\n",
        "    train_dataset = torchvision.datasets.SVHN(\n",
        "        root=data_dir, split='train', transform=train_transform, download=True\n",
        "    )\n",
        "    valid_dataset = torchvision.datasets.SVHN(\n",
        "        root=data_dir, split='train', transform=valid_transform, download=True\n",
        "    )\n",
        "    test_dataset  = torchvision.datasets.SVHN(\n",
        "        root=data_dir, split='test', transform=test_transform, download=True\n",
        "    )\n",
        "\n",
        "    return train_dataset, valid_dataset, test_dataset    \n",
        "\n",
        "\n",
        "def get_data_loader(batch_size, valid_size=0.2, data_dir=SVHN_DATASET_DIR):\n",
        "    \"\"\"Get the train, validation and test data loaders\"\"\"\n",
        "\n",
        "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
        "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
        "\n",
        "    # get transform\n",
        "    train_transform, valid_transform, test_transform = get_data_transform()\n",
        "\n",
        "    # load dataset\n",
        "    train_dataset, valid_dataset, test_dataset = get_dataset(\n",
        "        train_transform, valid_transform, test_transform, data_dir\n",
        "    )\n",
        "    \n",
        "    # split the data\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    np.random.shuffle(indices)\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "    # shuffle\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    loader_settings = {\n",
        "        'batch_size': batch_size,\n",
        "        'num_workers': 1,\n",
        "        'pin_memory': torch.cuda.is_available()\n",
        "    }\n",
        "\n",
        "    # get dataloader objects\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, **loader_settings\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_dataset, sampler=valid_sampler, **loader_settings\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, shuffle=False, **loader_settings\n",
        "    )\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqzuxO9Fk4Go"
      },
      "source": [
        "# loading some data\n",
        "train_transform, _, _ = get_data_transform()\n",
        "train_set = torchvision.datasets.SVHN(SVHN_DATASET_DIR, \n",
        "                                      split='train', \n",
        "                                      transform=train_transform, \n",
        "                                      target_transform=None, \n",
        "                                      download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9xAgu5Mk4K6"
      },
      "source": [
        "# let's see some of the images\n",
        "def convert_to_imshow_format(image):\n",
        "    # first convert back to [0,1] range from [-1,1] range - approximately...\n",
        "    image = image / 2 + 0.5\n",
        "    image = image.numpy()\n",
        "    \n",
        "    # for single channel images \n",
        "    if image.shape[0] == 1:\n",
        "      return np.squeeze(image)\n",
        "    \n",
        "    # for images with more than 1 channel\n",
        "    elif image.shape[0] > 1:\n",
        "      return image.transpose(1, 2, 0)\n",
        "\n",
        "def grid_plot(images, labels, ncols=5):\n",
        "  # plot a grid of images of shape (len(images) / ncols, ncols)\n",
        "  nrows = np.int(np.ceil(len(labels) / ncols))\n",
        "\n",
        "  # plot images with labels\n",
        "  fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(2 * ncols, 2 * nrows))\n",
        "  for idx, image in enumerate(images):\n",
        "    if len(axes.shape) == 1:\n",
        "      axes[idx].imshow(convert_to_imshow_format(image))\n",
        "      axes[idx].set_title(CLASSES[labels[idx].item()])\n",
        "      axes[idx].set_xticks([])\n",
        "      axes[idx].set_yticks([])\n",
        "    else:  \n",
        "      i, j = np.unravel_index(idx, (nrows, ncols))\n",
        "      axes[i, j].imshow(convert_to_imshow_format(image))\n",
        "      axes[i, j].set_title(CLASSES[labels[idx].item()])\n",
        "      axes[i, j].set_xticks([])\n",
        "      axes[i, j].set_yticks([])\n",
        "\n",
        "trainloader = DataLoader(train_set, batch_size=20, shuffle=False)\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "grid_plot(images, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjmUUh4Ik4Ne"
      },
      "source": [
        "# define hyper-parmeters\n",
        "batch_size = 32\n",
        "learning_rate = 0.00005\n",
        "num_epochs = 10\n",
        "whight_decay = learning_rate/110\n",
        "\n",
        "# Load the dataset\n",
        "train_loader, valid_loader, test_loader = get_data_loader(batch_size, \n",
        "                                                          valid_size=0.2, \n",
        "                                                          )\n",
        "# device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# loss criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# model\n",
        "model = SVHN_CNN().to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), \n",
        "                             lr=learning_rate, \n",
        "                             amsgrad=True, \n",
        "                             weight_decay=whight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMC3qd93k4QA"
      },
      "source": [
        "# dict for saving logs \n",
        "logger = {\n",
        "    'loss': [],\n",
        "    'train_acc': [],\n",
        "    'valid_acc': [],\n",
        "    'epochs': [],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naUpgNJvk4Sj"
      },
      "source": [
        "# training loop\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train() # put in training mode\n",
        "    running_loss = 0.0\n",
        "    epoch_time = time.time()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # send them to device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)           # forward pass\n",
        "        loss = criterion(outputs, labels) # calculate the loss\n",
        "        optimizer.zero_grad()             # zero the parameter gradients\n",
        "        loss.backward()                   # backpropagation\n",
        "        optimizer.step()                  # update parameters\n",
        "        \n",
        "        # calculate loss\n",
        "        running_loss += loss.data.item()\n",
        "        running_loss /= len(trainloader)\n",
        "        \n",
        "    # Calculate training + valid sets accuracy\n",
        "    train_accuracy, _ = calculate_accuracy(model, train_loader, device)\n",
        "    valid_accuracy, _ = calculate_accuracy(model, valid_loader, device)\n",
        "    log = \"Epoch: {} | Loss: {:.6f} | Training accuracy: {:.3f}% | valid accuracy: {:.3f}% | \".format(epoch\n",
        "    , running_loss, train_accuracy, valid_accuracy)\n",
        "    epoch_time = time.time() - epoch_time\n",
        "    log += \"Epoch Time: {:.2f} secs\".format(epoch_time)\n",
        "    print(log)\n",
        "    \n",
        "    # save log into logger\n",
        "    logger['loss'].append(running_loss)\n",
        "    logger['train_acc'].append(train_accuracy)\n",
        "    logger['valid_acc'].append(valid_accuracy)\n",
        "    logger['epochs'].append(epoch)\n",
        "\n",
        "    # save the model\n",
        "    state = {\n",
        "        'net':        model.state_dict(),\n",
        "        'epoch':      epoch,\n",
        "        'loss':       loss,\n",
        "        'train_acc':  train_accuracy,\n",
        "        'valid_acc':  valid_accuracy,\n",
        "        'logger':     logger,\n",
        "    }\n",
        "    torch.save(state, f'{SVHN_CHECKPOINT_DIR}/{MODEL_NAME}_{epoch}.pth')\n",
        "print('==> Finished Training ...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR6y-4Ofk4VD"
      },
      "source": [
        "# load saved model\n",
        "model = SVHN_CNN().to(device)\n",
        "state = torch.load(f'{SVHN_CHECKPOINT_DIR}/{MODEL_NAME}_{num_epochs - 1}.pth', map_location=device)\n",
        "model.load_state_dict(state['net'])\n",
        "\n",
        "# calculte test accuracy\n",
        "test_accuracy, confusion_matrix = calculate_accuracy(model, test_loader, device)\n",
        "print()\n",
        "print('Test accuracy: {}'.format(test_accuracy))\n",
        "\n",
        "\n",
        "# plot confusion matrix\n",
        "fig, ax = plt.subplots(1,1,figsize=(8, 8))\n",
        "ax.matshow(confusion_matrix, aspect='auto', vmin=0, vmax=1000, cmap=plt.get_cmap('Blues'))\n",
        "plt.ylabel('Actual Category')\n",
        "plt.yticks(range(10), CLASSES.values())\n",
        "plt.xlabel('Predicted Category')\n",
        "plt.xticks(range(10), CLASSES.values())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmsnXUtik4Xc"
      },
      "source": [
        "print_msg_box('Test accuracy: ' + str(np.round(test_accuracy, 2)) + '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YXZT1Hkk4aL"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(12,6))\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# plot accuracy\n",
        "p1 = ax.plot(logger['epochs'], logger['train_acc'], linewidth=2, label='train\\naccuracy')\n",
        "p2 = ax.plot(logger['epochs'], logger['valid_acc'], linewidth=2, label='validation\\naccuracy')\n",
        "ax.set_xticks(range(0, num_epochs + 1, 1))\n",
        "ax.set_xticklabels(range(0, num_epochs + 1, 1))\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy [%]')\n",
        "ax.set_title('Model Accuracy and Loss')\n",
        "ax.xaxis.grid()\n",
        "ax1 = ax.twinx()\n",
        "ax1.set_ylabel('Loss')\n",
        "p3 = ax1.plot(logger['epochs'], logger['loss'], linewidth=2, label='loss')\n",
        "\n",
        "# Add legend\n",
        "lns = p1 + p2 + p3\n",
        "labs = [l.get_label() for l in lns]\n",
        "ax.legend(lns, labs, loc='upper center', ncol=3, frameon=False, bbox_to_anchor=(0.35, 1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XhyDXp_k4cl"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    \"\"\"Add Gaussian noise to Pytorch's tensor\"\"\"\n",
        "    def __init__(self, mean=0., std=1., a=0.005):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.a = a\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + self.a * torch.randn(tensor.size()) * self.std + self.mean\n",
        "      \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'mean={self.mean}, std={self.std}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAztUm6SoSbn"
      },
      "source": [
        "# load saved model\n",
        "model = SVHN_CNN().to(device)\n",
        "state = torch.load(f'{SVHN_CHECKPOINT_DIR}/{MODEL_NAME}_{num_epochs - 1}.pth', map_location=device)\n",
        "model.load_state_dict(state['net'])\n",
        "\n",
        "\n",
        "a_list = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1., 2., 5.]\n",
        "noisy_test_accuracy = []\n",
        "\n",
        "for a in a_list:\n",
        "  # preper the transform with noise\n",
        "  test_transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "      AddGaussianNoise(a=a),  # adding gaussian noise\n",
        "  ])\n",
        "\n",
        "  # get data set\n",
        "  test_dataset = torchvision.datasets.SVHN(SVHN_DATASET_DIR, \n",
        "                                        split='test', \n",
        "                                        transform=test_transform, \n",
        "                                        target_transform=None, \n",
        "                                        download=True)\n",
        "\n",
        "  # get data loader\n",
        "  loader_settings = {\n",
        "      'batch_size': 32,\n",
        "      'num_workers': 1,\n",
        "      'pin_memory': torch.cuda.is_available()\n",
        "  }\n",
        "  test_loader = DataLoader(test_dataset, shuffle=False, **loader_settings)\n",
        "\n",
        "  # calculte test accuracy\n",
        "  test_accuracy, _ = calculate_accuracy(model, test_loader, device)\n",
        "  noisy_test_accuracy.append(test_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ks2HY2Xk4fD"
      },
      "source": [
        "# plot noisy test accuracy for different noise values\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12,6))\n",
        "fig.patch.set_facecolor('white')\n",
        "p1 = ax.semilogx(a_list, noisy_test_accuracy, linewidth=2, label='noisy test accuracy')\n",
        "ax.set_xticks(a_list)\n",
        "ax.set_xticklabels(a_list)\n",
        "ax.set_xlabel('Noise factor $a$')\n",
        "ax.set_ylabel('Accuracy [%]')\n",
        "ax.set_title('Model Accuracy over noisy test dataset: image + a * N(0, 1)')\n",
        "ax.scatter(a_list[2], noisy_test_accuracy[2], color='red', label='$a=0.005$')\n",
        "ax.text(a_list[2], noisy_test_accuracy[2] - 5, 'acc = ' + str(np.round(noisy_test_accuracy[2], 2)) + '%')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q74ZYnA0o_DB"
      },
      "source": [
        "Comparing the performence of this model which was trained on data without data augmentation to the model trained on data with data augmentation (specifically data with added gaussuan noise) we see that for noise factor $a=0.005$ there is no much difference: $93.92$% for model that was trained on augmented data while $93.87$% for model that was trained original clean data. But, we can see a difference between the models for larger noise factors. There is a factor of $2$ difference in the noise factor for similar performence. The performence of the model that was trained on data with gaussian noise drops to accuracy of $70$% for noise factor of $a=0.1$, while performence of the model that was trained on clean data drops to accuracy of $70$% already for noise factor of $a=0.5$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rYW-Ar0lmxg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHChcnSWJ4Pr"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCD0qIciXq7g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}